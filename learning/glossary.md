---
title: "Glossary"
summary: "Concise definitions for common LLM terms."
type: note
level: beginner
topics: [glossary]
updated: 2025-10-26
---

- LLM: Large Language Model trained to predict next tokens.
- Token: A chunk of text the model processes; not always a word.
- Context window: Max tokens the model can attend to at once.
- Embedding: Vector representation of text for similarity search.
- Temperature: Controls randomness; higher = more diverse outputs.
- Top-p (nucleus): Samples from top cumulative probability mass.
- RAG: Retrieval-Augmented Generation; uses external docs at inference.
- Hallucination: Confident but unsupported or incorrect output.

