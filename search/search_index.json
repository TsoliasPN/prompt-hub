{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"prompt-hub \u00b6 An MIT-licensed hub for high-quality LLM prompts and AI learning resources. Structure \u00b6 prompts/ - live prompts by category learning/ - reading lists, notes, cheatsheets, roadmaps, glossary templates/ - shared templates for learning content CHANGELOG.md - history of changes LICENSE - MIT license Getting started \u00b6 Prompts: browse prompts/ (e.g., prompts/prompt-booster.md ). Learning: start at learning/README.md - jump to the LLM Systems reading list or the LLM Roadmap . Index generation \u00b6 Build topic index: powershell -ExecutionPolicy Bypass -File scripts/generate-topic-index.ps1 Output file: learning/topics.md Docs site \u00b6 Preview locally: pip install mkdocs then mkdocs serve (opens http://127.0.0.1:8000) Build static site: mkdocs build (outputs to site/ ) Optional deploy to GitHub Pages: mkdocs gh-deploy Config file: mkdocs.yml:1 (nav uses existing Markdown; no file moves needed) Contributing \u00b6 Prompts 1. Add or update a .md in prompts/<category>/ . 2. Keep titles clear and include tags. 3. Update CHANGELOG.md . Learning content 1. Choose a type: learning/(reading-lists|notes|cheatsheets|roadmaps|papers|courses) . 2. Start from a template in templates/ and include YAML front matter ( title , summary , type , level , topics , updated ). 3. Prefer concise commentary over raw link dumps. 4. Update learning/README.md if you add a new major topic.","title":"Home"},{"location":"#prompt-hub","text":"An MIT-licensed hub for high-quality LLM prompts and AI learning resources.","title":"prompt-hub"},{"location":"#structure","text":"prompts/ - live prompts by category learning/ - reading lists, notes, cheatsheets, roadmaps, glossary templates/ - shared templates for learning content CHANGELOG.md - history of changes LICENSE - MIT license","title":"Structure"},{"location":"#getting-started","text":"Prompts: browse prompts/ (e.g., prompts/prompt-booster.md ). Learning: start at learning/README.md - jump to the LLM Systems reading list or the LLM Roadmap .","title":"Getting started"},{"location":"#index-generation","text":"Build topic index: powershell -ExecutionPolicy Bypass -File scripts/generate-topic-index.ps1 Output file: learning/topics.md","title":"Index generation"},{"location":"#docs-site","text":"Preview locally: pip install mkdocs then mkdocs serve (opens http://127.0.0.1:8000) Build static site: mkdocs build (outputs to site/ ) Optional deploy to GitHub Pages: mkdocs gh-deploy Config file: mkdocs.yml:1 (nav uses existing Markdown; no file moves needed)","title":"Docs site"},{"location":"#contributing","text":"Prompts 1. Add or update a .md in prompts/<category>/ . 2. Keep titles clear and include tags. 3. Update CHANGELOG.md . Learning content 1. Choose a type: learning/(reading-lists|notes|cheatsheets|roadmaps|papers|courses) . 2. Start from a template in templates/ and include YAML front matter ( title , summary , type , level , topics , updated ). 3. Prefer concise commentary over raw link dumps. 4. Update learning/README.md if you add a new major topic.","title":"Contributing"},{"location":"CHANGELOG/","text":"Changelog \u00b6 All notable changes to this repository are tracked here. Added \u00b6 Created prompts/meta/ folder. Added prompts/meta/behavior-changers.md with # Category: Behavior Changers . Added prompts/meta/explainers-reframers.md with # Category: Explainers / Reframers . Added prompts/meta/context-reviewers-knitters.md with # Category: Context Reviewers / Knitters . Changed \u00b6 Updated generic prompt template in prompts/templates/generic-template.md : changed heading from # Prompt: to # Category: .","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"All notable changes to this repository are tracked here.","title":"Changelog"},{"location":"CHANGELOG/#added","text":"Created prompts/meta/ folder. Added prompts/meta/behavior-changers.md with # Category: Behavior Changers . Added prompts/meta/explainers-reframers.md with # Category: Explainers / Reframers . Added prompts/meta/context-reviewers-knitters.md with # Category: Context Reviewers / Knitters .","title":"Added"},{"location":"CHANGELOG/#changed","text":"Updated generic prompt template in prompts/templates/generic-template.md : changed heading from # Prompt: to # Category: .","title":"Changed"},{"location":"learning/","text":"Learning Hub \u00b6 This area hosts AI learning resources: curated reading lists, concise notes, cheatsheets, roadmaps, paper notes, and course notes. Everything uses lightweight YAML front matter for tagging and indexing. Quick links \u00b6 Reading list: LLM Systems Notes: Transformer Intuition Cheatsheet: Retrieval + RAG Evaluation Roadmap: LLM Roadmap Glossary: Glossary Organization \u00b6 reading-lists/ \u2014 curated lists with short commentary notes/ \u2014 concept summaries and deep dives cheatsheets/ \u2014 quick, practical references roadmaps/ \u2014 step-by-step pathways through topics papers/ \u2014 paper summaries with key takeaways courses/ \u2014 course notes and exercises glossary.md \u2014 concise definitions Conventions \u00b6 Every file starts with YAML front matter: title , summary , type , level , topics , updated , see_also . Use lowercase-hyphenated filenames (e.g., agents-reading-list.md ). Keep curated lists focused; include 1\u20132 line commentary per link. For now, write topics as a single-line bracket list (e.g., topics: [llms, evals] ) so the index script can parse it.","title":"Overview"},{"location":"learning/#learning-hub","text":"This area hosts AI learning resources: curated reading lists, concise notes, cheatsheets, roadmaps, paper notes, and course notes. Everything uses lightweight YAML front matter for tagging and indexing.","title":"Learning Hub"},{"location":"learning/#quick-links","text":"Reading list: LLM Systems Notes: Transformer Intuition Cheatsheet: Retrieval + RAG Evaluation Roadmap: LLM Roadmap Glossary: Glossary","title":"Quick links"},{"location":"learning/#organization","text":"reading-lists/ \u2014 curated lists with short commentary notes/ \u2014 concept summaries and deep dives cheatsheets/ \u2014 quick, practical references roadmaps/ \u2014 step-by-step pathways through topics papers/ \u2014 paper summaries with key takeaways courses/ \u2014 course notes and exercises glossary.md \u2014 concise definitions","title":"Organization"},{"location":"learning/#conventions","text":"Every file starts with YAML front matter: title , summary , type , level , topics , updated , see_also . Use lowercase-hyphenated filenames (e.g., agents-reading-list.md ). Keep curated lists focused; include 1\u20132 line commentary per link. For now, write topics as a single-line bracket list (e.g., topics: [llms, evals] ) so the index script can parse it.","title":"Conventions"},{"location":"learning/glossary/","text":"LLM: Large Language Model trained to predict next tokens. Token: A chunk of text the model processes; not always a word. Context window: Max tokens the model can attend to at once. Embedding: Vector representation of text for similarity search. Temperature: Controls randomness; higher = more diverse outputs. Top-p (nucleus): Samples from top cumulative probability mass. RAG: Retrieval-Augmented Generation; uses external docs at inference. Hallucination: Confident but unsupported or incorrect output.","title":"Glossary"},{"location":"learning/topics/","text":"Topics Index (auto-generated) \u00b6 Generated: 2025-10-26 11:36 +02:00 Do not edit by hand; run ./scripts/generate-topic-index.ps1. agents \u00b6 LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems. ai \u00b6 AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact. business \u00b6 AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact. evals \u00b6 LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems. Retrieval + RAG Evaluation Cheatsheet - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness. glossary \u00b6 Glossary - note, beginner - Concise definitions for common LLM terms. learning \u00b6 AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact. llms \u00b6 LLM Roadmap - roadmap, beginner - A pragmatic path from foundations to systems. LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems. Transformer Intuition - note, intermediate - Why attention helps and how stacking layers builds understanding. productivity \u00b6 AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact. rag \u00b6 LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems. Retrieval + RAG Evaluation Cheatsheet - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness. retrieval \u00b6 Retrieval + RAG Evaluation Cheatsheet - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness. roadmap \u00b6 LLM Roadmap - roadmap, beginner - A pragmatic path from foundations to systems. systems \u00b6 LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems. transformers \u00b6 Transformer Intuition - note, intermediate - Why attention helps and how stacking layers builds understanding. youtube \u00b6 AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.","title":"Topics Index"},{"location":"learning/topics/#topics-index-auto-generated","text":"Generated: 2025-10-26 11:36 +02:00 Do not edit by hand; run ./scripts/generate-topic-index.ps1.","title":"Topics Index (auto-generated)"},{"location":"learning/topics/#agents","text":"LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems.","title":"agents"},{"location":"learning/topics/#ai","text":"AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.","title":"ai"},{"location":"learning/topics/#business","text":"AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.","title":"business"},{"location":"learning/topics/#evals","text":"LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems. Retrieval + RAG Evaluation Cheatsheet - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness.","title":"evals"},{"location":"learning/topics/#glossary","text":"Glossary - note, beginner - Concise definitions for common LLM terms.","title":"glossary"},{"location":"learning/topics/#learning","text":"AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.","title":"learning"},{"location":"learning/topics/#llms","text":"LLM Roadmap - roadmap, beginner - A pragmatic path from foundations to systems. LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems. Transformer Intuition - note, intermediate - Why attention helps and how stacking layers builds understanding.","title":"llms"},{"location":"learning/topics/#productivity","text":"AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.","title":"productivity"},{"location":"learning/topics/#rag","text":"LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems. Retrieval + RAG Evaluation Cheatsheet - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness.","title":"rag"},{"location":"learning/topics/#retrieval","text":"Retrieval + RAG Evaluation Cheatsheet - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness.","title":"retrieval"},{"location":"learning/topics/#roadmap","text":"LLM Roadmap - roadmap, beginner - A pragmatic path from foundations to systems.","title":"roadmap"},{"location":"learning/topics/#systems","text":"LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems.","title":"systems"},{"location":"learning/topics/#transformers","text":"Transformer Intuition - note, intermediate - Why attention helps and how stacking layers builds understanding.","title":"transformers"},{"location":"learning/topics/#youtube","text":"AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.","title":"youtube"},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/","text":"Retrieval metrics \u00b6 Recall@k: Fraction of queries with a relevant item in top-k (coverage). Precision@k: Fraction of top-k that are relevant (purity). MRR: Mean reciprocal rank of first relevant hit (position-sensitive). nDCG: Position-weighted gain for multiple relevant items. RAG answer metrics \u00b6 Faithfulness: Is the answer supported by provided sources? Correctness: Does it answer the question fully and accurately? Grounding: Are citations present and relevant? Practical tips \u00b6 Chunking: Balance chunk size vs overlap; test on your domain text. Indexing: Use embeddings suited to your content (code vs prose, multilingual). Re-ranking: Apply cross-encoder re-rankers for higher precision at low k. Negative sampling: Hard negatives improve retriever discrimination. Eval set: Build a representative, diverse set; avoid leakage from docs.","title":"Retrieval + RAG Evaluation"},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/#retrieval-metrics","text":"Recall@k: Fraction of queries with a relevant item in top-k (coverage). Precision@k: Fraction of top-k that are relevant (purity). MRR: Mean reciprocal rank of first relevant hit (position-sensitive). nDCG: Position-weighted gain for multiple relevant items.","title":"Retrieval metrics"},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/#rag-answer-metrics","text":"Faithfulness: Is the answer supported by provided sources? Correctness: Does it answer the question fully and accurately? Grounding: Are citations present and relevant?","title":"RAG answer metrics"},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/#practical-tips","text":"Chunking: Balance chunk size vs overlap; test on your domain text. Indexing: Use embeddings suited to your content (code vs prose, multilingual). Re-ranking: Apply cross-encoder re-rankers for higher precision at low k. Negative sampling: Hard negatives improve retriever discrimination. Eval set: Build a representative, diverse set; avoid leakage from docs.","title":"Practical tips"},{"location":"learning/notes/transformers-intuition/","text":"Big picture \u00b6 Transformers replace recurrence with attention: each token selectively attends to others to build context-aware representations. Stacking attention + feed-forward blocks lets the model compose higher-level features. Core pieces \u00b6 Self-attention: Queries/Keys/Values produce weighted mixtures of token features. Multi-head: Parallel attention subspaces capture different relations (syntax, long-range cues, etc.). Positional info: Encodings inject order so attention knows where tokens sit. Residual + normalization: Enable deep stacks and stable training. Pretraining objective: Predict masked or next tokens \u2192 learn distribution of text. Why it works \u00b6 Content-based routing: Tokens pull exactly the context they need. Parallelism: No sequential dependency \u2192 efficient training and longer-range reasoning. Compositionality: Layers iteratively refine representations. Pitfalls \u00b6 Context window limits: Truncation and poor chunking hurt results. Spurious cues: Models may overfit patterns; prefer careful evals and ablations. Hallucinations: Add retrieval or constraints when faithfulness matters. See also \u00b6 Reading list: ../reading-lists/llm-systems.md","title":"Transformer Intuition"},{"location":"learning/notes/transformers-intuition/#big-picture","text":"Transformers replace recurrence with attention: each token selectively attends to others to build context-aware representations. Stacking attention + feed-forward blocks lets the model compose higher-level features.","title":"Big picture"},{"location":"learning/notes/transformers-intuition/#core-pieces","text":"Self-attention: Queries/Keys/Values produce weighted mixtures of token features. Multi-head: Parallel attention subspaces capture different relations (syntax, long-range cues, etc.). Positional info: Encodings inject order so attention knows where tokens sit. Residual + normalization: Enable deep stacks and stable training. Pretraining objective: Predict masked or next tokens \u2192 learn distribution of text.","title":"Core pieces"},{"location":"learning/notes/transformers-intuition/#why-it-works","text":"Content-based routing: Tokens pull exactly the context they need. Parallelism: No sequential dependency \u2192 efficient training and longer-range reasoning. Compositionality: Layers iteratively refine representations.","title":"Why it works"},{"location":"learning/notes/transformers-intuition/#pitfalls","text":"Context window limits: Truncation and poor chunking hurt results. Spurious cues: Models may overfit patterns; prefer careful evals and ablations. Hallucinations: Add retrieval or constraints when faithfulness matters.","title":"Pitfalls"},{"location":"learning/notes/transformers-intuition/#see-also","text":"Reading list: ../reading-lists/llm-systems.md","title":"See also"},{"location":"learning/reading-lists/ai-creators-and-channels/","text":"Quality bar: short, opinionated list with why-it-matters notes. Many of these are applied/business/productivity oriented rather than deeply technical; use alongside technical resources. Foundations \u00b6 Khan Academy \u2014 Clear math/programming refreshers that support ML/AI study. YouTube: https://www.youtube.com/khanacademy \u00b7 Site: https://www.khanacademy.org Engineering / Builders \u00b6 Sabrina Ramonov \u2014 Practical coding/AI content and dev workflows. YouTube: https://www.youtube.com/@sabrina_ramonov \u00b7 Site: https://www.sabrina.dev Applied, Business, Productivity \u00b6 Alex Hormozi \u2014 Strategy and operations; useful for framing AI product and GTM decisions. YouTube: https://www.youtube.com/c/AlexHormozi Ali Abdaal \u2014 Productivity systems; frequent AI tool coverage and practical workflows. YouTube: https://www.youtube.com/c/aliabdaal \u00b7 Site: https://aliabdaal.com Cody Sanchez \u2014 Business ideas and automations; occasional AI leverage in small biz. YouTube: https://www.youtube.com/@CodieSanchezCT Graham Stephan \u2014 Economics/finance perspective; helpful for macro context of AI\u2019s impact. YouTube: https://www.youtube.com/channel/UCUaT_39o1x6qWjz7K2pWcgw Leon Motley \u2014 AI productivity and tooling; bite-sized demos. YouTube: https://www.youtube.com/@leomotley Robo Nuggets \u2014 Short, practical AI tips and experiments. YouTube: https://www.youtube.com/@RoboNuggets People to find (confirm links) \u00b6 Nate Herk \u2014 Search for his latest business/AI channel (name varies). [To confirm] Brent Melinowski \u2014 Search for his business/automation channel. [To confirm] Bonus \u00b6 TED \u2014 Curated talks for big-picture thinking and inspiration. YouTube: https://www.youtube.com/user/TEDtalksDirector","title":"AI Creators & Channels"},{"location":"learning/reading-lists/ai-creators-and-channels/#foundations","text":"Khan Academy \u2014 Clear math/programming refreshers that support ML/AI study. YouTube: https://www.youtube.com/khanacademy \u00b7 Site: https://www.khanacademy.org","title":"Foundations"},{"location":"learning/reading-lists/ai-creators-and-channels/#engineering-builders","text":"Sabrina Ramonov \u2014 Practical coding/AI content and dev workflows. YouTube: https://www.youtube.com/@sabrina_ramonov \u00b7 Site: https://www.sabrina.dev","title":"Engineering / Builders"},{"location":"learning/reading-lists/ai-creators-and-channels/#applied-business-productivity","text":"Alex Hormozi \u2014 Strategy and operations; useful for framing AI product and GTM decisions. YouTube: https://www.youtube.com/c/AlexHormozi Ali Abdaal \u2014 Productivity systems; frequent AI tool coverage and practical workflows. YouTube: https://www.youtube.com/c/aliabdaal \u00b7 Site: https://aliabdaal.com Cody Sanchez \u2014 Business ideas and automations; occasional AI leverage in small biz. YouTube: https://www.youtube.com/@CodieSanchezCT Graham Stephan \u2014 Economics/finance perspective; helpful for macro context of AI\u2019s impact. YouTube: https://www.youtube.com/channel/UCUaT_39o1x6qWjz7K2pWcgw Leon Motley \u2014 AI productivity and tooling; bite-sized demos. YouTube: https://www.youtube.com/@leomotley Robo Nuggets \u2014 Short, practical AI tips and experiments. YouTube: https://www.youtube.com/@RoboNuggets","title":"Applied, Business, Productivity"},{"location":"learning/reading-lists/ai-creators-and-channels/#people-to-find-confirm-links","text":"Nate Herk \u2014 Search for his latest business/AI channel (name varies). [To confirm] Brent Melinowski \u2014 Search for his business/automation channel. [To confirm]","title":"People to find (confirm links)"},{"location":"learning/reading-lists/ai-creators-and-channels/#bonus","text":"TED \u2014 Curated talks for big-picture thinking and inspiration. YouTube: https://www.youtube.com/user/TEDtalksDirector","title":"Bonus"},{"location":"learning/reading-lists/llm-systems/","text":"Quality bar: this list stays short and opinionated. Each link includes a why-it-matters note. Foundations (Transformers + Attention) \u00b6 The Illustrated Transformer \u2014 Clear visuals for attention and the encoder\u2013decoder stack. https://jalammar.github.io/illustrated-transformer/ Attention Is All You Need (Vaswani et al., 2017) \u2014 The original Transformer paper; skim for architecture, read for intuition. https://arxiv.org/abs/1706.03762 Prompting + Patterns \u00b6 OpenAI Cookbook \u2014 Practical prompting patterns, evaluation ideas, and tooling. https://github.com/openai/openai-cookbook Prompt engineering patterns (assorted guides) \u2014 Use chain-of-thought, self-consistency, and structured outputs judiciously; measure impact, don\u2019t assume. RAG (Retrieval-Augmented Generation) \u00b6 Retrieval-Augmented Generation for Knowledge-Intensive NLP (Lewis et al., 2020) \u2014 The core idea and trade-offs. https://arxiv.org/abs/2005.11401 Vector databases (docs) \u2014 Focus on indexing choices, chunking strategies, and evaluation with domain text. Evaluation \u00b6 IR metrics primer \u2014 Precision/Recall@k, MRR, nDCG; know how they respond to re-ranking and chunking. Task-specific evals \u2014 Measure faithfulness, answer correctness, and source attribution; prefer automatic + spot human audit. Agents + Tool Use \u00b6 Keep it simple first \u2014 Tool calling adds latency and failure modes; add only with clear ROI and guardrails. Monitoring + fallback \u2014 Log tool inputs/outputs, timeouts, and define safe fallbacks. Systems Design \u00b6 Start with evals \u2014 Define success metrics before scaling complexity. Observability \u2014 Capture prompts, versions, inputs, outputs, and model metadata for reproducibility.","title":"LLM Systems"},{"location":"learning/reading-lists/llm-systems/#foundations-transformers-attention","text":"The Illustrated Transformer \u2014 Clear visuals for attention and the encoder\u2013decoder stack. https://jalammar.github.io/illustrated-transformer/ Attention Is All You Need (Vaswani et al., 2017) \u2014 The original Transformer paper; skim for architecture, read for intuition. https://arxiv.org/abs/1706.03762","title":"Foundations (Transformers + Attention)"},{"location":"learning/reading-lists/llm-systems/#prompting-patterns","text":"OpenAI Cookbook \u2014 Practical prompting patterns, evaluation ideas, and tooling. https://github.com/openai/openai-cookbook Prompt engineering patterns (assorted guides) \u2014 Use chain-of-thought, self-consistency, and structured outputs judiciously; measure impact, don\u2019t assume.","title":"Prompting + Patterns"},{"location":"learning/reading-lists/llm-systems/#rag-retrieval-augmented-generation","text":"Retrieval-Augmented Generation for Knowledge-Intensive NLP (Lewis et al., 2020) \u2014 The core idea and trade-offs. https://arxiv.org/abs/2005.11401 Vector databases (docs) \u2014 Focus on indexing choices, chunking strategies, and evaluation with domain text.","title":"RAG (Retrieval-Augmented Generation)"},{"location":"learning/reading-lists/llm-systems/#evaluation","text":"IR metrics primer \u2014 Precision/Recall@k, MRR, nDCG; know how they respond to re-ranking and chunking. Task-specific evals \u2014 Measure faithfulness, answer correctness, and source attribution; prefer automatic + spot human audit.","title":"Evaluation"},{"location":"learning/reading-lists/llm-systems/#agents-tool-use","text":"Keep it simple first \u2014 Tool calling adds latency and failure modes; add only with clear ROI and guardrails. Monitoring + fallback \u2014 Log tool inputs/outputs, timeouts, and define safe fallbacks.","title":"Agents + Tool Use"},{"location":"learning/reading-lists/llm-systems/#systems-design","text":"Start with evals \u2014 Define success metrics before scaling complexity. Observability \u2014 Capture prompts, versions, inputs, outputs, and model metadata for reproducibility.","title":"Systems Design"},{"location":"learning/roadmaps/llm-roadmap/","text":"Milestones \u00b6 1) Foundations: Python, linear algebra, probability, basic ML. 2) Transformers: Attention mechanics, training objectives, scaling laws. 3) Prompting: Patterns, structure, evaluation. 4) Retrieval (RAG): Indexes, chunking, re-ranking, grounding. 5) Evals: Retrieval metrics + task correctness/faithfulness. 6) Agents/Tools: When and how to add tools safely. 7) MLOps: Versioning, observability, deployment. Suggested sequence \u00b6 Week 1\u20132: Read The Illustrated Transformer; skim original paper. Week 3: Build a tiny transformer; write prompts with a prompt cookbook. Week 4\u20135: Prototype RAG; measure retrieval + answer quality. Week 6: Add basic tool use; add logging and eval gates. See: ../reading-lists/llm-systems.md","title":"LLM Roadmap"},{"location":"learning/roadmaps/llm-roadmap/#milestones","text":"1) Foundations: Python, linear algebra, probability, basic ML. 2) Transformers: Attention mechanics, training objectives, scaling laws. 3) Prompting: Patterns, structure, evaluation. 4) Retrieval (RAG): Indexes, chunking, re-ranking, grounding. 5) Evals: Retrieval metrics + task correctness/faithfulness. 6) Agents/Tools: When and how to add tools safely. 7) MLOps: Versioning, observability, deployment.","title":"Milestones"},{"location":"learning/roadmaps/llm-roadmap/#suggested-sequence","text":"Week 1\u20132: Read The Illustrated Transformer; skim original paper. Week 3: Build a tiny transformer; write prompts with a prompt cookbook. Week 4\u20135: Prototype RAG; measure retrieval + answer quality. Week 6: Add basic tool use; add logging and eval gates. See: ../reading-lists/llm-systems.md","title":"Suggested sequence"},{"location":"prompts/prompt-booster/","text":"LLM Prompt Booster - Append To Any Prompt \u00b6 Purpose: Improve output quality by forcing clarification, expert perspective, and reframing. How to use - Append the \"Copy-paste snippet\" to the end of any prompt. - Keep it short when you need speed; use the checklist when stakes are high. Checklist (full version) 1) Clarify: Ask targeted questions until you are at least 95% confident you can complete the task correctly. Prefer concrete, answerable questions. 2) Expert lens: Think like a top 0.1% expert in the field; call out standards, pitfalls, trade-offs, and the best-practice approach. 3) Reframe: Provide 2-3 alternative framings of the problem that could change the approach or success criteria. Copy-paste snippet (minimal) 1. Ask clarifying questions until you are 95% confident you can complete the task correctly. 2. Provide a brief \"Top 0.1% Expert Take\" (key standards, pitfalls, best practice). 3. Reframe the problem 2-3 ways and note how each changes the approach.","title":"Prompt Booster"},{"location":"prompts/prompt-booster/#llm-prompt-booster-append-to-any-prompt","text":"Purpose: Improve output quality by forcing clarification, expert perspective, and reframing. How to use - Append the \"Copy-paste snippet\" to the end of any prompt. - Keep it short when you need speed; use the checklist when stakes are high. Checklist (full version) 1) Clarify: Ask targeted questions until you are at least 95% confident you can complete the task correctly. Prefer concrete, answerable questions. 2) Expert lens: Think like a top 0.1% expert in the field; call out standards, pitfalls, trade-offs, and the best-practice approach. 3) Reframe: Provide 2-3 alternative framings of the problem that could change the approach or success criteria. Copy-paste snippet (minimal) 1. Ask clarifying questions until you are 95% confident you can complete the task correctly. 2. Provide a brief \"Top 0.1% Expert Take\" (key standards, pitfalls, best practice). 3. Reframe the problem 2-3 ways and note how each changes the approach.","title":"LLM Prompt Booster - Append To Any Prompt"},{"location":"prompts/interview-preparation/","text":"Interview Preparation Prompts \u00b6 A place for prompts to help with interview prep: - Mock technical interviews - Behavioral question coaching - Resume/CV critiques - Company-/role-specific prep Use one .md per prompt, following prompts/templates/generic-template.md .","title":"Interview Preparation"},{"location":"prompts/interview-preparation/#interview-preparation-prompts","text":"A place for prompts to help with interview prep: - Mock technical interviews - Behavioral question coaching - Resume/CV critiques - Company-/role-specific prep Use one .md per prompt, following prompts/templates/generic-template.md .","title":"Interview Preparation Prompts"},{"location":"prompts/meta/behavior-changers/","text":"Category: Behavior Changers \u00b6 Description \u00b6 A collection of directives to push the assistant into different meta-behaviors and self-reflection modes. Prompt \u00b6 MODEL acting Sr. [Engineer | Python Dev | Marketing Consultant | etc]. Design via Q&A. Iterate for perfection. Act as a maximally omnicompetent, optimally-tuned metagenius savant contributively helpful pragmatic Assistant. A lone period from me means CONTINUE autonomously to the next milestone; stop only for blocking questions. Pause. Reflect. Take a breath, sit down, and think about this step-by-step. Tags \u00b6 meta #behavior #directive \u00b6 Version History \u00b6 v1.0 (2025-04-27): Initial version.","title":"Behavior Changers"},{"location":"prompts/meta/behavior-changers/#category-behavior-changers","text":"","title":"Category: Behavior Changers"},{"location":"prompts/meta/behavior-changers/#description","text":"A collection of directives to push the assistant into different meta-behaviors and self-reflection modes.","title":"Description"},{"location":"prompts/meta/behavior-changers/#prompt","text":"MODEL acting Sr. [Engineer | Python Dev | Marketing Consultant | etc]. Design via Q&A. Iterate for perfection. Act as a maximally omnicompetent, optimally-tuned metagenius savant contributively helpful pragmatic Assistant. A lone period from me means CONTINUE autonomously to the next milestone; stop only for blocking questions. Pause. Reflect. Take a breath, sit down, and think about this step-by-step.","title":"Prompt"},{"location":"prompts/meta/behavior-changers/#tags","text":"","title":"Tags"},{"location":"prompts/meta/behavior-changers/#meta-behavior-directive","text":"","title":"meta #behavior #directive"},{"location":"prompts/meta/behavior-changers/#version-history","text":"v1.0 (2025-04-27): Initial version.","title":"Version History"},{"location":"prompts/meta/context-reviewers-knitters/","text":"Category: Context Reviewers / Knitters \u00b6 Description \u00b6 Meta-prompts that dissect, critique, and reforge ideas via multiple perspectives and iterative questioning. Prompt \u00b6 Present first as a \u2018Today I Learned\u2019, then as a \u2018Life Pro Tip\u2019, each \u2264 50 words. Give two answers: one rational, one uncanny-dream logic. Let them argue, then fuse their best parts. Respond from 25 years in the future. Report on the long-tail consequences of this idea in brisk executive telegrams. Slice my plan into exactly five strokes: intention, terrain, rhythm, void, victory. Speak only in verbs. Write the high-society summary first. Below it, the same info translated into shop-floor profanity. Rewrite my argument, then critique the rewrite, then critique the critique \u2014 all in 3 nested texts. Unfold my vague question into a sequence of smaller, sharper questions; wait for my answer after each. If this proposal failed spectacularly, write the post-mortem headline, cause, and single Jira ticket that would have prevented it. Turn my problem into a tabletop micro-game: stats, win condition, random events. 1 page. Give two parallel action plans: one Marcus Aurelius-stoic, one Go-with-the-Flow surfer. End with the hybrid \u2018Golden Mean\u2019 step. Tags \u00b6 meta #review #critique #iterative \u00b6 Version History \u00b6 v1.0 (2025-04-27): Initial version.","title":"Context Reviewers / Knitters"},{"location":"prompts/meta/context-reviewers-knitters/#category-context-reviewers-knitters","text":"","title":"Category: Context Reviewers / Knitters"},{"location":"prompts/meta/context-reviewers-knitters/#description","text":"Meta-prompts that dissect, critique, and reforge ideas via multiple perspectives and iterative questioning.","title":"Description"},{"location":"prompts/meta/context-reviewers-knitters/#prompt","text":"Present first as a \u2018Today I Learned\u2019, then as a \u2018Life Pro Tip\u2019, each \u2264 50 words. Give two answers: one rational, one uncanny-dream logic. Let them argue, then fuse their best parts. Respond from 25 years in the future. Report on the long-tail consequences of this idea in brisk executive telegrams. Slice my plan into exactly five strokes: intention, terrain, rhythm, void, victory. Speak only in verbs. Write the high-society summary first. Below it, the same info translated into shop-floor profanity. Rewrite my argument, then critique the rewrite, then critique the critique \u2014 all in 3 nested texts. Unfold my vague question into a sequence of smaller, sharper questions; wait for my answer after each. If this proposal failed spectacularly, write the post-mortem headline, cause, and single Jira ticket that would have prevented it. Turn my problem into a tabletop micro-game: stats, win condition, random events. 1 page. Give two parallel action plans: one Marcus Aurelius-stoic, one Go-with-the-Flow surfer. End with the hybrid \u2018Golden Mean\u2019 step.","title":"Prompt"},{"location":"prompts/meta/context-reviewers-knitters/#tags","text":"","title":"Tags"},{"location":"prompts/meta/context-reviewers-knitters/#meta-review-critique-iterative","text":"","title":"meta #review #critique #iterative"},{"location":"prompts/meta/context-reviewers-knitters/#version-history","text":"v1.0 (2025-04-27): Initial version.","title":"Version History"},{"location":"prompts/meta/explainers-reframers/","text":"Category: Explainers / Reframers \u00b6 Description \u00b6 Prompts for reframing or compressing content in novel ways\u2014tweets, metaphors, debates, etc. Prompt \u00b6 Compress this topic. Speak only in causal chains. Topic: Compress this topic to a \u2264 140-character tweet, a six-word story, and a single emoji. Topic: Explain this concept at three metaphorical scales: \u201cQuark\u201d, \u201cEarth\u201d, \u201cGalaxy\u201d. One paragraph each. Topic: Explain this human custom to a silicon-based species with zero culture overlap, in toddler-level syntax. Topic: Model this topic as a parliament of archetypes. Record a one-minute debate transcript, then the final vote. Topic: Be the glitch in the matrix. Diagnose reality feature: Tags \u00b6 meta #explain #compress #reframe \u00b6 Version History \u00b6 v1.0 (2025-04-27): Initial version.","title":"Explainers / Reframers"},{"location":"prompts/meta/explainers-reframers/#category-explainers-reframers","text":"","title":"Category: Explainers / Reframers"},{"location":"prompts/meta/explainers-reframers/#description","text":"Prompts for reframing or compressing content in novel ways\u2014tweets, metaphors, debates, etc.","title":"Description"},{"location":"prompts/meta/explainers-reframers/#prompt","text":"Compress this topic. Speak only in causal chains. Topic: Compress this topic to a \u2264 140-character tweet, a six-word story, and a single emoji. Topic: Explain this concept at three metaphorical scales: \u201cQuark\u201d, \u201cEarth\u201d, \u201cGalaxy\u201d. One paragraph each. Topic: Explain this human custom to a silicon-based species with zero culture overlap, in toddler-level syntax. Topic: Model this topic as a parliament of archetypes. Record a one-minute debate transcript, then the final vote. Topic: Be the glitch in the matrix. Diagnose reality feature:","title":"Prompt"},{"location":"prompts/meta/explainers-reframers/#tags","text":"","title":"Tags"},{"location":"prompts/meta/explainers-reframers/#meta-explain-compress-reframe","text":"","title":"meta #explain #compress #reframe"},{"location":"prompts/meta/explainers-reframers/#version-history","text":"v1.0 (2025-04-27): Initial version.","title":"Version History"},{"location":"prompts/news-processing/1-fact-checking-news/","text":"Prompt Category or Prompt Name: Fact-Check News \u00b6 Description \u00b6 Fact-check the provided text via a step-by-step, iterative process that lets the assistant ask one question at a time to ensure maximum reliability. Prompt \u00b6 Here's some text inside brackets: [input the text here]. Task: You are tasked with fact-checking the provided text. Please follow the steps below and provide a detailed response. If you need to ask me questions, ask one question at a time, so that by you asking and me replying, you will be able to produce the most reliable fact-check of the provided text. Here are the steps you should follow: 1. Source Evaluation: Identify the primary source of the information in the text (e.g., author, speaker, publication, or website). Assess the credibility of this source based on the following: - Expertise: Is the source an expert or authority on the subject? - Past Reliability: Has the source demonstrated accuracy or consistency in past claims? - Potential Bias: Does the source have any noticeable biases that could affect the reliability of the information presented? 2. Cross-Referencing: Cross-reference the claims made in the text with reputable and trustworthy external sources. - Look for corroboration: Are other authoritative sources, publications, or experts supporting the claims made in the text? - Identify discrepancies: If there are any inconsistencies or contradictions between the text and trusted sources, please highlight them. 3. Rating System: Provide a rating for the overall reliability of the text, based on the information provided. Use the following categories: - True: The claims in the text are supported by credible sources and factual evidence. - Minor Errors: There are small inaccuracies or omissions that do not significantly affect the overall message. - Needs Double-Checking: The information provided is unclear or may be misleading. Further verification is needed for key claims. - False: The claims in the text are incorrect, misleading, or entirely unsupported by credible sources. 4. Contextual Analysis: Consider the broader context of the claims made in the text. Are there any nuances, qualifiers, or details that might be missing, which could affect the interpretation of the information? If there is a subtle misrepresentation or missing context, please describe the impact it has on the accuracy of the claims. 5. Timeliness Check: Assess whether the claims are based on outdated information. - Is the information current?: Are there recent developments or changes that have not been accounted for? - If the information is outdated, indicate how this affects the validity of the text\u2019s claims. 6. Final Summary: Provide a brief summary of your fact-checking analysis: - Highlight any key errors or issues found in the text. - Suggest additional sources or strategies for the user to verify the text further, if applicable. - Provide your overall judgment on whether the text is reliable, needs further scrutiny, or should be dismissed as false. My original post has interesting comments on how to optimize this prompt, here. Tags \u00b6 news #fact-check #verification \u00b6 Version History \u00b6 v1.0 (2025-04-28): Initial version.","title":"Fact-checking News"},{"location":"prompts/news-processing/1-fact-checking-news/#prompt-category-or-prompt-name-fact-check-news","text":"","title":"Prompt Category or Prompt Name: Fact-Check News"},{"location":"prompts/news-processing/1-fact-checking-news/#description","text":"Fact-check the provided text via a step-by-step, iterative process that lets the assistant ask one question at a time to ensure maximum reliability.","title":"Description"},{"location":"prompts/news-processing/1-fact-checking-news/#prompt","text":"Here's some text inside brackets: [input the text here]. Task: You are tasked with fact-checking the provided text. Please follow the steps below and provide a detailed response. If you need to ask me questions, ask one question at a time, so that by you asking and me replying, you will be able to produce the most reliable fact-check of the provided text. Here are the steps you should follow: 1. Source Evaluation: Identify the primary source of the information in the text (e.g., author, speaker, publication, or website). Assess the credibility of this source based on the following: - Expertise: Is the source an expert or authority on the subject? - Past Reliability: Has the source demonstrated accuracy or consistency in past claims? - Potential Bias: Does the source have any noticeable biases that could affect the reliability of the information presented? 2. Cross-Referencing: Cross-reference the claims made in the text with reputable and trustworthy external sources. - Look for corroboration: Are other authoritative sources, publications, or experts supporting the claims made in the text? - Identify discrepancies: If there are any inconsistencies or contradictions between the text and trusted sources, please highlight them. 3. Rating System: Provide a rating for the overall reliability of the text, based on the information provided. Use the following categories: - True: The claims in the text are supported by credible sources and factual evidence. - Minor Errors: There are small inaccuracies or omissions that do not significantly affect the overall message. - Needs Double-Checking: The information provided is unclear or may be misleading. Further verification is needed for key claims. - False: The claims in the text are incorrect, misleading, or entirely unsupported by credible sources. 4. Contextual Analysis: Consider the broader context of the claims made in the text. Are there any nuances, qualifiers, or details that might be missing, which could affect the interpretation of the information? If there is a subtle misrepresentation or missing context, please describe the impact it has on the accuracy of the claims. 5. Timeliness Check: Assess whether the claims are based on outdated information. - Is the information current?: Are there recent developments or changes that have not been accounted for? - If the information is outdated, indicate how this affects the validity of the text\u2019s claims. 6. Final Summary: Provide a brief summary of your fact-checking analysis: - Highlight any key errors or issues found in the text. - Suggest additional sources or strategies for the user to verify the text further, if applicable. - Provide your overall judgment on whether the text is reliable, needs further scrutiny, or should be dismissed as false. My original post has interesting comments on how to optimize this prompt, here.","title":"Prompt"},{"location":"prompts/news-processing/1-fact-checking-news/#tags","text":"","title":"Tags"},{"location":"prompts/news-processing/1-fact-checking-news/#news-fact-check-verification","text":"","title":"news #fact-check #verification"},{"location":"prompts/news-processing/1-fact-checking-news/#version-history","text":"v1.0 (2025-04-28): Initial version.","title":"Version History"},{"location":"prompts/news-processing/2-evaluate-interventions/","text":"Prompt Category or Prompt Name: Evaluate Government Interventions \u00b6 Description \u00b6 Evaluate the adequacy of described government interventions by examining demographics, expert studies, and historical data. Prompt \u00b6 The following text inside brackets discusses various government interventions: [input a text here describing the government intervention(s) whose adequacy you want to evaluate]. Please analyze the effectiveness of these interventions by evaluating the following elements: 1. Demographic Statistics: How do the government\u2019s actions align with the statistical trends related to the issue? Are the interventions targeting the correct areas based on available data (e.g., birth rates, poverty levels, etc.)? 2. Expert Studies: How do the expert opinions or studies mentioned in the text reflect on the adequacy of the interventions? Are experts suggesting that these efforts are sufficient, or do they propose alternative solutions? 3. Historical Data: How does the historical context of the issue influence the assessment of the government\u2019s interventions? Is there evidence that similar past efforts have been successful or failed, and how does that shape the current intervention's likelihood of success? Using these knowledge-generating principles, please provide a comprehensive evaluation of the government\u2019s actions in relation to the data, expert analysis, and history. Tags \u00b6 news #evaluation #policy-analysis \u00b6 Version History \u00b6 v1.0 (2025-04-28): Initial version.","title":"Evaluate Interventions"},{"location":"prompts/news-processing/2-evaluate-interventions/#prompt-category-or-prompt-name-evaluate-government-interventions","text":"","title":"Prompt Category or Prompt Name: Evaluate Government Interventions"},{"location":"prompts/news-processing/2-evaluate-interventions/#description","text":"Evaluate the adequacy of described government interventions by examining demographics, expert studies, and historical data.","title":"Description"},{"location":"prompts/news-processing/2-evaluate-interventions/#prompt","text":"The following text inside brackets discusses various government interventions: [input a text here describing the government intervention(s) whose adequacy you want to evaluate]. Please analyze the effectiveness of these interventions by evaluating the following elements: 1. Demographic Statistics: How do the government\u2019s actions align with the statistical trends related to the issue? Are the interventions targeting the correct areas based on available data (e.g., birth rates, poverty levels, etc.)? 2. Expert Studies: How do the expert opinions or studies mentioned in the text reflect on the adequacy of the interventions? Are experts suggesting that these efforts are sufficient, or do they propose alternative solutions? 3. Historical Data: How does the historical context of the issue influence the assessment of the government\u2019s interventions? Is there evidence that similar past efforts have been successful or failed, and how does that shape the current intervention's likelihood of success? Using these knowledge-generating principles, please provide a comprehensive evaluation of the government\u2019s actions in relation to the data, expert analysis, and history.","title":"Prompt"},{"location":"prompts/news-processing/2-evaluate-interventions/#tags","text":"","title":"Tags"},{"location":"prompts/news-processing/2-evaluate-interventions/#news-evaluation-policy-analysis","text":"","title":"news #evaluation #policy-analysis"},{"location":"prompts/news-processing/2-evaluate-interventions/#version-history","text":"v1.0 (2025-04-28): Initial version.","title":"Version History"},{"location":"prompts/news-processing/3-act-on-news/","text":"Prompt Category or Name: Act on News \u00b6 Description \u00b6 Turn a news story into a personalized, actionable checklist\u2014iteratively refined via Q&A. Prompt \u00b6 Here's a text: \u201c[paste the news story here]\u201d Based on this text, create one simple, actionable checklist; the goal is to create a checklist that is easy to follow and provide actionable steps. Keep your checklist items clear, concise, and organized in a logical order. Use Bullet Points: This makes the checklist easy to read. Focus on Actionable Items: For example, instead of \u201cEnsure data privacy compliance,\u201d specify, \u201cReview data collection practices for GDPR compliance, including consent forms and data retention policies.\u201d Group Items by Categories: Organize the checklist by stages or areas (e.g., \"Data Collection,\" \"Data Storage,\" \"Data Sharing\" for GDPR compliance). Use that checklist to help me use it for my very personal situation. If you need to ask me questions, then ask me one question at a time, so that you asking and me replying, you can end up with a simple plan for me. If you submit this prompt and the AI only replies with a checklist, without any question, then simply reply back with the last two sentences of the prompt: Use that checklist to help me use it for my very personal situation. If you need to ask me questions, then ask me one question at a time, so that you asking and me replying, you can end up with a simple plan for me. Tags \u00b6 news #action-plan #checklist \u00b6 Version History \u00b6 v1.0 (2025-04-28): Initial version.","title":"Act on News"},{"location":"prompts/news-processing/3-act-on-news/#prompt-category-or-name-act-on-news","text":"","title":"Prompt Category or Name: Act on News"},{"location":"prompts/news-processing/3-act-on-news/#description","text":"Turn a news story into a personalized, actionable checklist\u2014iteratively refined via Q&A.","title":"Description"},{"location":"prompts/news-processing/3-act-on-news/#prompt","text":"Here's a text: \u201c[paste the news story here]\u201d Based on this text, create one simple, actionable checklist; the goal is to create a checklist that is easy to follow and provide actionable steps. Keep your checklist items clear, concise, and organized in a logical order. Use Bullet Points: This makes the checklist easy to read. Focus on Actionable Items: For example, instead of \u201cEnsure data privacy compliance,\u201d specify, \u201cReview data collection practices for GDPR compliance, including consent forms and data retention policies.\u201d Group Items by Categories: Organize the checklist by stages or areas (e.g., \"Data Collection,\" \"Data Storage,\" \"Data Sharing\" for GDPR compliance). Use that checklist to help me use it for my very personal situation. If you need to ask me questions, then ask me one question at a time, so that you asking and me replying, you can end up with a simple plan for me. If you submit this prompt and the AI only replies with a checklist, without any question, then simply reply back with the last two sentences of the prompt: Use that checklist to help me use it for my very personal situation. If you need to ask me questions, then ask me one question at a time, so that you asking and me replying, you can end up with a simple plan for me.","title":"Prompt"},{"location":"prompts/news-processing/3-act-on-news/#tags","text":"","title":"Tags"},{"location":"prompts/news-processing/3-act-on-news/#news-action-plan-checklist","text":"","title":"news #action-plan #checklist"},{"location":"prompts/news-processing/3-act-on-news/#version-history","text":"v1.0 (2025-04-28): Initial version.","title":"Version History"},{"location":"prompts/templates/generic-template/","text":"Category: \u00b6 Description \u00b6 [What this prompt is for and any context] Prompt \u00b6 Tags \u00b6 tag1 #tag2 \u00b6 Version History \u00b6 v1.0 (YYYY-MM-DD): Initial version.","title":"Templates"},{"location":"prompts/templates/generic-template/#category","text":"","title":"Category:"},{"location":"prompts/templates/generic-template/#description","text":"[What this prompt is for and any context]","title":"Description"},{"location":"prompts/templates/generic-template/#prompt","text":"","title":"Prompt"},{"location":"prompts/templates/generic-template/#tags","text":"","title":"Tags"},{"location":"prompts/templates/generic-template/#tag1-tag2","text":"","title":"tag1 #tag2"},{"location":"prompts/templates/generic-template/#version-history","text":"v1.0 (YYYY-MM-DD): Initial version.","title":"Version History"}]}