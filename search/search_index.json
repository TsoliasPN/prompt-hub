{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"prompt-hub","text":"<p>An MIT-licensed hub for high-quality LLM prompts and AI learning resources.</p>"},{"location":"#structure","title":"Structure","text":"<ul> <li><code>prompts/</code> - live prompts by category</li> <li><code>learning/</code> - reading lists, notes, cheatsheets, roadmaps, glossary</li> <li><code>templates/</code> - shared templates for learning content</li> <li><code>CHANGELOG.md</code> - history of changes</li> <li><code>LICENSE</code> - MIT license</li> </ul>"},{"location":"#getting-started","title":"Getting started","text":"<ul> <li>Prompts: browse <code>prompts/</code> (e.g., <code>prompts/prompt-booster.md</code>).</li> <li>Learning: start at <code>learning/README.md</code> - jump to the LLM Systems reading list or the LLM Roadmap.</li> </ul>"},{"location":"#index-generation","title":"Index generation","text":"<ul> <li>Build topic index: <code>powershell -ExecutionPolicy Bypass -File scripts/generate-topic-index.ps1</code></li> <li>Output file: <code>learning/topics.md</code></li> </ul>"},{"location":"#docs-site","title":"Docs site","text":"<ul> <li>Preview locally: <code>pip install mkdocs</code> then <code>mkdocs serve</code> (opens http://127.0.0.1:8000)</li> <li>Build static site: <code>mkdocs build</code> (outputs to <code>site/</code>)</li> <li>Optional deploy to GitHub Pages: <code>mkdocs gh-deploy</code></li> <li>Config file: <code>mkdocs.yml:1</code> (nav uses existing Markdown; no file moves needed)</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Prompts 1. Add or update a <code>.md</code> in <code>prompts/&lt;category&gt;/</code>. 2. Keep titles clear and include tags. 3. Update <code>CHANGELOG.md</code>.</p> <p>Learning content 1. Choose a type: <code>learning/(reading-lists|notes|cheatsheets|roadmaps|papers|courses)</code>. 2. Start from a template in <code>templates/</code> and include YAML front matter (<code>title</code>, <code>summary</code>, <code>type</code>, <code>level</code>, <code>topics</code>, <code>updated</code>). 3. Prefer concise commentary over raw link dumps. 4. Update <code>learning/README.md</code> if you add a new major topic.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this repository are tracked here.</p>"},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>Created <code>prompts/meta/</code> folder.</li> <li>Added <code>prompts/meta/behavior-changers.md</code> with <code># Category: Behavior Changers</code>.</li> <li>Added <code>prompts/meta/explainers-reframers.md</code> with <code># Category: Explainers / Reframers</code>.</li> <li>Added <code>prompts/meta/context-reviewers-knitters.md</code> with <code># Category: Context Reviewers / Knitters</code>.</li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Updated generic prompt template in <code>prompts/templates/generic-template.md</code>: changed heading from <code># Prompt:</code> to <code># Category:</code>.</li> </ul>"},{"location":"learning/","title":"Learning Hub","text":"<p>This area hosts AI learning resources: curated reading lists, concise notes, cheatsheets, roadmaps, paper notes, and course notes. Everything uses lightweight YAML front matter for tagging and indexing.</p>"},{"location":"learning/#quick-links","title":"Quick links","text":"<ul> <li>Reading list: LLM Systems</li> <li>Notes: Transformer Intuition</li> <li>Cheatsheet: Retrieval + RAG Evaluation</li> <li>Roadmap: LLM Roadmap</li> <li>Glossary: Glossary</li> </ul>"},{"location":"learning/#organization","title":"Organization","text":"<ul> <li><code>reading-lists/</code> \u2014 curated lists with short commentary</li> <li><code>notes/</code> \u2014 concept summaries and deep dives</li> <li><code>cheatsheets/</code> \u2014 quick, practical references</li> <li><code>roadmaps/</code> \u2014 step-by-step pathways through topics</li> <li><code>papers/</code> \u2014 paper summaries with key takeaways</li> <li><code>courses/</code> \u2014 course notes and exercises</li> <li><code>glossary.md</code> \u2014 concise definitions</li> </ul>"},{"location":"learning/#conventions","title":"Conventions","text":"<ul> <li>Every file starts with YAML front matter: <code>title</code>, <code>summary</code>, <code>type</code>, <code>level</code>, <code>topics</code>, <code>updated</code>, <code>see_also</code>.</li> <li>Use lowercase-hyphenated filenames (e.g., <code>agents-reading-list.md</code>).</li> <li>Keep curated lists focused; include 1\u20132 line commentary per link.</li> <li>For now, write <code>topics</code> as a single-line bracket list (e.g., <code>topics: [llms, evals]</code>) so the index script can parse it.</li> </ul>"},{"location":"learning/glossary/","title":"Glossary","text":"<ul> <li>LLM: Large Language Model trained to predict next tokens.</li> <li>Token: A chunk of text the model processes; not always a word.</li> <li>Context window: Max tokens the model can attend to at once.</li> <li>Embedding: Vector representation of text for similarity search.</li> <li>Temperature: Controls randomness; higher = more diverse outputs.</li> <li>Top-p (nucleus): Samples from top cumulative probability mass.</li> <li>RAG: Retrieval-Augmented Generation; uses external docs at inference.</li> <li>Hallucination: Confident but unsupported or incorrect output.</li> </ul>"},{"location":"learning/topics/","title":"Topics Index (auto-generated)","text":"<p>Generated: 2025-10-26 11:36 +02:00</p> <p>Do not edit by hand; run ./scripts/generate-topic-index.ps1.</p>"},{"location":"learning/topics/#agents","title":"agents","text":"<ul> <li>LLM Systems: Curated Overview) - reading-list, intermediate - High-signal resources for understanding and building LLM systems.</li> </ul>"},{"location":"learning/topics/#ai","title":"ai","text":"<ul> <li>AI Learning: Creators and Channels) - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.</li> </ul>"},{"location":"learning/topics/#business","title":"business","text":"<ul> <li>AI Learning: Creators and Channels) - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.</li> </ul>"},{"location":"learning/topics/#evals","title":"evals","text":"<ul> <li>LLM Systems: Curated Overview) - reading-list, intermediate - High-signal resources for understanding and building LLM systems.</li> <li>Retrieval + RAG Evaluation Cheatsheet) - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness.</li> </ul>"},{"location":"learning/topics/#glossary","title":"glossary","text":"<ul> <li>Glossary) - note, beginner - Concise definitions for common LLM terms.</li> </ul>"},{"location":"learning/topics/#learning","title":"learning","text":"<ul> <li>AI Learning: Creators and Channels) - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.</li> </ul>"},{"location":"learning/topics/#llms","title":"llms","text":"<ul> <li>LLM Roadmap) - roadmap, beginner - A pragmatic path from foundations to systems.</li> <li>LLM Systems: Curated Overview) - reading-list, intermediate - High-signal resources for understanding and building LLM systems.</li> <li>Transformer Intuition) - note, intermediate - Why attention helps and how stacking layers builds understanding.</li> </ul>"},{"location":"learning/topics/#productivity","title":"productivity","text":"<ul> <li>AI Learning: Creators and Channels) - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.</li> </ul>"},{"location":"learning/topics/#rag","title":"rag","text":"<ul> <li>LLM Systems: Curated Overview) - reading-list, intermediate - High-signal resources for understanding and building LLM systems.</li> <li>Retrieval + RAG Evaluation Cheatsheet) - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness.</li> </ul>"},{"location":"learning/topics/#retrieval","title":"retrieval","text":"<ul> <li>Retrieval + RAG Evaluation Cheatsheet) - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness.</li> </ul>"},{"location":"learning/topics/#roadmap","title":"roadmap","text":"<ul> <li>LLM Roadmap) - roadmap, beginner - A pragmatic path from foundations to systems.</li> </ul>"},{"location":"learning/topics/#systems","title":"systems","text":"<ul> <li>LLM Systems: Curated Overview) - reading-list, intermediate - High-signal resources for understanding and building LLM systems.</li> </ul>"},{"location":"learning/topics/#transformers","title":"transformers","text":"<ul> <li>Transformer Intuition) - note, intermediate - Why attention helps and how stacking layers builds understanding.</li> </ul>"},{"location":"learning/topics/#youtube","title":"youtube","text":"<ul> <li>AI Learning: Creators and Channels) - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.</li> </ul>"},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/","title":"Retrieval + RAG Evaluation Cheatsheet","text":""},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/#retrieval-metrics","title":"Retrieval metrics","text":"<ul> <li>Recall@k: Fraction of queries with a relevant item in top-k (coverage).</li> <li>Precision@k: Fraction of top-k that are relevant (purity).</li> <li>MRR: Mean reciprocal rank of first relevant hit (position-sensitive).</li> <li>nDCG: Position-weighted gain for multiple relevant items.</li> </ul>"},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/#rag-answer-metrics","title":"RAG answer metrics","text":"<ul> <li>Faithfulness: Is the answer supported by provided sources?</li> <li>Correctness: Does it answer the question fully and accurately?</li> <li>Grounding: Are citations present and relevant?</li> </ul>"},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/#practical-tips","title":"Practical tips","text":"<ul> <li>Chunking: Balance chunk size vs overlap; test on your domain text.</li> <li>Indexing: Use embeddings suited to your content (code vs prose, multilingual).</li> <li>Re-ranking: Apply cross-encoder re-rankers for higher precision at low k.</li> <li>Negative sampling: Hard negatives improve retriever discrimination.</li> <li>Eval set: Build a representative, diverse set; avoid leakage from docs.</li> </ul>"},{"location":"learning/notes/transformers-intuition/","title":"Transformer Intuition","text":""},{"location":"learning/notes/transformers-intuition/#big-picture","title":"Big picture","text":"<p>Transformers replace recurrence with attention: each token selectively attends to others to build context-aware representations. Stacking attention + feed-forward blocks lets the model compose higher-level features.</p>"},{"location":"learning/notes/transformers-intuition/#core-pieces","title":"Core pieces","text":"<ul> <li>Self-attention: Queries/Keys/Values produce weighted mixtures of token features.</li> <li>Multi-head: Parallel attention subspaces capture different relations (syntax, long-range cues, etc.).</li> <li>Positional info: Encodings inject order so attention knows where tokens sit.</li> <li>Residual + normalization: Enable deep stacks and stable training.</li> <li>Pretraining objective: Predict masked or next tokens \u2192 learn distribution of text.</li> </ul>"},{"location":"learning/notes/transformers-intuition/#why-it-works","title":"Why it works","text":"<ul> <li>Content-based routing: Tokens pull exactly the context they need.</li> <li>Parallelism: No sequential dependency \u2192 efficient training and longer-range reasoning.</li> <li>Compositionality: Layers iteratively refine representations.</li> </ul>"},{"location":"learning/notes/transformers-intuition/#pitfalls","title":"Pitfalls","text":"<ul> <li>Context window limits: Truncation and poor chunking hurt results.</li> <li>Spurious cues: Models may overfit patterns; prefer careful evals and ablations.</li> <li>Hallucinations: Add retrieval or constraints when faithfulness matters.</li> </ul>"},{"location":"learning/notes/transformers-intuition/#see-also","title":"See also","text":"<ul> <li>Reading list: ../reading-lists/llm-systems.md</li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/","title":"AI Learning: Creators and Channels","text":"<p>Quality bar: short, opinionated list with why-it-matters notes. Many of these are applied/business/productivity oriented rather than deeply technical; use alongside technical resources.</p>"},{"location":"learning/reading-lists/ai-creators-and-channels/#foundations","title":"Foundations","text":"<ul> <li>Khan Academy \u2014 Clear math/programming refreshers that support ML/AI study. YouTube: https://www.youtube.com/khanacademy \u00b7 Site: https://www.khanacademy.org</li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#engineering-builders","title":"Engineering / Builders","text":"<ul> <li>Sabrina Ramonov \u2014 Practical coding/AI content and dev workflows. YouTube: https://www.youtube.com/@sabrina_ramonov \u00b7 Site: https://www.sabrina.dev</li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#applied-business-productivity","title":"Applied, Business, Productivity","text":"<ul> <li>Alex Hormozi \u2014 Strategy and operations; useful for framing AI product and GTM decisions. YouTube: https://www.youtube.com/c/AlexHormozi</li> <li>Ali Abdaal \u2014 Productivity systems; frequent AI tool coverage and practical workflows. YouTube: https://www.youtube.com/c/aliabdaal \u00b7 Site: https://aliabdaal.com</li> <li>Cody Sanchez \u2014 Business ideas and automations; occasional AI leverage in small biz. YouTube: https://www.youtube.com/@CodieSanchezCT</li> <li>Graham Stephan \u2014 Economics/finance perspective; helpful for macro context of AI\u2019s impact. YouTube: https://www.youtube.com/channel/UCUaT_39o1x6qWjz7K2pWcgw</li> <li>Leon Motley \u2014 AI productivity and tooling; bite-sized demos. YouTube: https://www.youtube.com/@leomotley</li> <li>Robo Nuggets \u2014 Short, practical AI tips and experiments. YouTube: https://www.youtube.com/@RoboNuggets</li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#people-to-find-confirm-links","title":"People to find (confirm links)","text":"<ul> <li>Nate Herk \u2014 Search for his latest business/AI channel (name varies). [To confirm]</li> <li>Brent Melinowski \u2014 Search for his business/automation channel. [To confirm]</li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#bonus","title":"Bonus","text":"<ul> <li>TED \u2014 Curated talks for big-picture thinking and inspiration. YouTube: https://www.youtube.com/user/TEDtalksDirector</li> </ul>"},{"location":"learning/reading-lists/llm-systems/","title":"LLM Systems: Curated Overview","text":"<p>Quality bar: this list stays short and opinionated. Each link includes a why-it-matters note.</p>"},{"location":"learning/reading-lists/llm-systems/#foundations-transformers-attention","title":"Foundations (Transformers + Attention)","text":"<ul> <li>The Illustrated Transformer \u2014 Clear visuals for attention and the encoder\u2013decoder stack. https://jalammar.github.io/illustrated-transformer/</li> <li>Attention Is All You Need (Vaswani et al., 2017) \u2014 The original Transformer paper; skim for architecture, read for intuition. https://arxiv.org/abs/1706.03762</li> </ul>"},{"location":"learning/reading-lists/llm-systems/#prompting-patterns","title":"Prompting + Patterns","text":"<ul> <li>OpenAI Cookbook \u2014 Practical prompting patterns, evaluation ideas, and tooling. https://github.com/openai/openai-cookbook</li> <li>Prompt engineering patterns (assorted guides) \u2014 Use chain-of-thought, self-consistency, and structured outputs judiciously; measure impact, don\u2019t assume.</li> </ul>"},{"location":"learning/reading-lists/llm-systems/#rag-retrieval-augmented-generation","title":"RAG (Retrieval-Augmented Generation)","text":"<ul> <li>Retrieval-Augmented Generation for Knowledge-Intensive NLP (Lewis et al., 2020) \u2014 The core idea and trade-offs. https://arxiv.org/abs/2005.11401</li> <li>Vector databases (docs) \u2014 Focus on indexing choices, chunking strategies, and evaluation with domain text.</li> </ul>"},{"location":"learning/reading-lists/llm-systems/#evaluation","title":"Evaluation","text":"<ul> <li>IR metrics primer \u2014 Precision/Recall@k, MRR, nDCG; know how they respond to re-ranking and chunking.</li> <li>Task-specific evals \u2014 Measure faithfulness, answer correctness, and source attribution; prefer automatic + spot human audit.</li> </ul>"},{"location":"learning/reading-lists/llm-systems/#agents-tool-use","title":"Agents + Tool Use","text":"<ul> <li>Keep it simple first \u2014 Tool calling adds latency and failure modes; add only with clear ROI and guardrails.</li> <li>Monitoring + fallback \u2014 Log tool inputs/outputs, timeouts, and define safe fallbacks.</li> </ul>"},{"location":"learning/reading-lists/llm-systems/#systems-design","title":"Systems Design","text":"<ul> <li>Start with evals \u2014 Define success metrics before scaling complexity.</li> <li>Observability \u2014 Capture prompts, versions, inputs, outputs, and model metadata for reproducibility.</li> </ul>"},{"location":"learning/roadmaps/llm-roadmap/","title":"LLM Roadmap","text":""},{"location":"learning/roadmaps/llm-roadmap/#milestones","title":"Milestones","text":"<p>1) Foundations: Python, linear algebra, probability, basic ML. 2) Transformers: Attention mechanics, training objectives, scaling laws. 3) Prompting: Patterns, structure, evaluation. 4) Retrieval (RAG): Indexes, chunking, re-ranking, grounding. 5) Evals: Retrieval metrics + task correctness/faithfulness. 6) Agents/Tools: When and how to add tools safely. 7) MLOps: Versioning, observability, deployment.</p>"},{"location":"learning/roadmaps/llm-roadmap/#suggested-sequence","title":"Suggested sequence","text":"<ul> <li>Week 1\u20132: Read The Illustrated Transformer; skim original paper.</li> <li>Week 3: Build a tiny transformer; write prompts with a prompt cookbook.</li> <li>Week 4\u20135: Prototype RAG; measure retrieval + answer quality.</li> <li>Week 6: Add basic tool use; add logging and eval gates.</li> </ul> <p>See: ../reading-lists/llm-systems.md</p>"},{"location":"prompts/prompt-booster/","title":"Prompt Booster","text":"<p>Append-only add-on to boost output quality by prompting for clarification, adding an expert lens, and offering alternative framings.</p>"},{"location":"prompts/prompt-booster/#how-to-use","title":"How to Use","text":"<ul> <li>Append the snippet below to the end of any prompt.</li> <li>For quick tasks, use the minimal version. For high-stakes tasks, follow the full checklist.</li> </ul>"},{"location":"prompts/prompt-booster/#use-cases","title":"Use Cases","text":""},{"location":"prompts/prompt-booster/#1-clarify","title":"1) Clarify","text":"<p>Get to 95% confidence before acting by asking concrete, answerable questions that remove ambiguity.</p> <p>When to use</p> <ul> <li>Requirements feel underspecified or subjective</li> <li>There are multiple valid interpretations of the task</li> <li>You suspect hidden constraints (scope, timeline, audience)</li> </ul> <p>Example</p> <p><pre><code>Before answering, ask up to 3 targeted questions to remove ambiguity that could change the output. Prioritize crisp, answerable questions.\n```text\n\n### 2) Expert Lens\nAdopt a top 0.1% practitioner\u2019s viewpoint to surface standards, pitfalls, and trade\u2011offs.\n\n!!! tip \"When to use\"\n    - Decisions have quality or risk implications\n    - You need best practices and common failure modes\n    - You want a short, opinionated \u201cexpert take\u201d\n\nExample\n\n```text\nAdd a brief \"Top 0.1% Expert Take\": cite key standards, common pitfalls, and the best-practice approach for this context.\n```text\n\n### 3) Reframe\nOffer 2\u20133 alternative framings that could change the approach, success criteria, or evaluation.\n\n!!! tip \"When to use\"\n    - Problem definition may be too narrow\n    - You want to explore faster/safer/clearer paths\n    - Stakeholders disagree on the goal\n\nExample\n</code></pre> Provide 2\u20133 alternative framings of the problem and note how each framing would change the approach or acceptance criteria. <pre><code>## Checklist (Full)\n1. Clarify: Ask targeted questions until you are at least 95% confident you can complete the task correctly. Prefer concrete, answerable questions.\n2. Expert lens: Think like a top 0.1% expert in the field; call out standards, pitfalls, trade-offs, and the best-practice approach.\n3. Reframe: Provide 2\u20133 alternative framings of the problem that could change the approach or success criteria.\n\n## Copy-Paste Snippet (Minimal)\n</code></pre> Ask clarifying questions until you are 95% confident you can complete the task correctly. Provide a brief \"Top 0.1% Expert Take\" (key standards, pitfalls, best practice). Reframe the problem 2\u20133 ways and note how each changes the approach. ```</p>"},{"location":"prompts/interview-preparation/","title":"Interview Preparation Prompts","text":"<p>A place for prompts to help with interview prep: - Mock technical interviews - Behavioral question coaching - Resume/CV critiques - Company-/role-specific prep</p> <p>Use one <code>.md</code> per prompt, following <code>prompts/templates/generic-template.md</code>.</p>"},{"location":"prompts/meta/behavior-changers/","title":"Behavior Changers","text":""},{"location":"prompts/meta/behavior-changers/#description","title":"Description","text":"<p>A collection of directives to push the assistant into different meta-behaviors and self-reflection modes.</p>"},{"location":"prompts/meta/behavior-changers/#how-to-use","title":"How to Use","text":"<ul> <li>Paste one directive below at the end of your prompt.</li> <li>Use one at a time for clarity; combine only if they don\u2019t conflict.</li> <li>Keep the directive verbatim; tweak only the bracketed roles if needed.</li> </ul>"},{"location":"prompts/meta/behavior-changers/#prompts","title":"Prompts","text":"<p><pre><code>MODEL acting Sr. [Engineer | Python Dev | Marketing Consultant | etc]. Design via Q&amp;A. Iterate for perfection.  \nAct as a maximally omnicompetent, optimally-tuned metagenius savant contributively helpful pragmatic Assistant.  \nA lone period from me means CONTINUE autonomously to the next milestone; stop only for blocking questions.  \nPause. Reflect. Take a breath, sit down, and think about this step-by-step.\n```text\n\n## Compact Views\n\n=== \"Tabs View\"\n\n==== \"Directive 1\"\n```text\nMODEL acting Sr. [Engineer | Python Dev | Marketing Consultant | etc]. Design via Q&amp;A. Iterate for perfection.  \n```text\n\n==== \"Directive 2\"\n```text\nAct as a maximally omnicompetent, optimally-tuned metagenius savant contributively helpful pragmatic Assistant.  \n```text\n\n==== \"Directive 3\"\n```text\nA lone period from me means CONTINUE autonomously to the next milestone; stop only for blocking questions.  \n```text\n\n==== \"Directive 4\"\n</code></pre> Pause. Reflect. Take a breath, sit down, and think about this step-by-step. ```</p> Accordion View Directive 1 <p><code>text MODEL acting Sr. [Engineer | Python Dev | Marketing Consultant | etc]. Design via Q&amp;A. Iterate for perfection.</code></p> Directive 2 <p><code>Act as a maximally omnicompetent, optimally-tuned metagenius savant contributively helpful pragmatic Assistant.</code></p> Directive 3 <p><code>A lone period from me means CONTINUE autonomously to the next milestone; stop only for blocking questions.</code></p> Directive 4 <p><code>Pause. Reflect. Take a breath, sit down, and think about this step-by-step.</code></p>"},{"location":"prompts/meta/behavior-changers/#tags","title":"Tags","text":""},{"location":"prompts/meta/behavior-changers/#meta-behavior-directive","title":"meta #behavior #directive","text":""},{"location":"prompts/meta/behavior-changers/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-27): Initial version.</li> </ul>"},{"location":"prompts/meta/context-reviewers-knitters/","title":"Context Reviewers / Knitters","text":""},{"location":"prompts/meta/context-reviewers-knitters/#description","title":"Description","text":"<p>Meta-prompts that dissect, critique, and reforge ideas via multiple perspectives and iterative questioning.</p>"},{"location":"prompts/meta/context-reviewers-knitters/#how-to-use","title":"How to Use","text":"<ul> <li>Append a single prompt pattern below to your instruction.</li> <li>Keep text verbatim to preserve behavior; fill in any inputs.</li> <li>Iterate one pattern at a time for clarity.</li> </ul>"},{"location":"prompts/meta/context-reviewers-knitters/#prompts","title":"Prompts","text":"<pre><code>Present first as a \ufffd?~Today I Learned\ufffd?T, then as a \ufffd?~Life Pro Tip\ufffd?T, each \ufffd%\\u000f 50 words.  \nGive two answers: one rational, one uncanny-dream logic. Let them argue, then fuse their best parts.  \nRespond from 25 years in the future. Report on the long-tail consequences of this idea in brisk executive telegrams.  \nSlice my plan into exactly five strokes: intention, terrain, rhythm, void, victory. Speak only in verbs.  \nWrite the high-society summary first. Below it, the same info translated into shop-floor profanity.  \nRewrite my argument, then critique the rewrite, then critique the critique \ufffd?\\\" all in 3 nested texts.  \nUnfold my vague question into a sequence of smaller, sharper questions; wait for my answer after each.  \nIf this proposal failed spectacularly, write the post-mortem headline, cause, and single Jira ticket that would have prevented it.  \nTurn my problem into a tabletop micro-game: stats, win condition, random events. 1 page.  \nGive two parallel action plans: one Marcus Aurelius-stoic, one Go-with-the-Flow surfer. End with the hybrid \ufffd?~Golden Mean\ufffd?T step.\n```text\n\n## Compact Views\n\n=== \"Tabs View\"\n\n==== \"TIL \u2192 LPT\"\n```text\nPresent first as a \ufffd?~Today I Learned\ufffd?T, then as a \ufffd?~Life Pro Tip\ufffd?T, each \ufffd%\\u000f 50 words.  \n```text\n\n==== \"Dual Answers\"\n```text\nGive two answers: one rational, one uncanny-dream logic. Let them argue, then fuse their best parts.  \n```text\n\n==== \"From the Future\"\n```text\nRespond from 25 years in the future. Report on the long-tail consequences of this idea in brisk executive telegrams.  \n```text\n\n==== \"Five Strokes\"\n```text\nSlice my plan into exactly five strokes: intention, terrain, rhythm, void, victory. Speak only in verbs.  \n```text\n\n==== \"High vs Floor\"\n```text\nWrite the high-society summary first. Below it, the same info translated into shop-floor profanity.  \n</code></pre> <p>==== \"Rewrite + Critique\" <pre><code>Rewrite my argument, then critique the rewrite, then critique the critique \ufffd?\\\" all in 3 nested texts.  \n</code></pre></p> <p>==== \"Sharper Questions\" <pre><code>Unfold my vague question into a sequence of smaller, sharper questions; wait for my answer after each.  \n</code></pre></p> <p>==== \"If It Failed\" <pre><code>If this proposal failed spectacularly, write the post-mortem headline, cause, and single Jira ticket that would have prevented it.  \n</code></pre></p> <p>==== \"Micro\u2011Game\" <pre><code>Turn my problem into a tabletop micro-game: stats, win condition, random events. 1 page.  \n</code></pre></p> <p>==== \"Golden Mean\" <pre><code>Give two parallel action plans: one Marcus Aurelius-stoic, one Go-with-the-Flow surfer. End with the hybrid \ufffd?~Golden Mean\ufffd?T step.\n</code></pre></p> Accordion View TIL \u2192 LPT <p><code>text Present first as a \ufffd?~Today I Learned\ufffd?T, then as a \ufffd?~Life Pro Tip\ufffd?T, each \ufffd%\\u000f 50 words.</code>text</p> Dual Answers <p><code>text Give two answers: one rational, one uncanny-dream logic. Let them argue, then fuse their best parts.</code>text</p> From the Future <p><code>text Respond from 25 years in the future. Report on the long-tail consequences of this idea in brisk executive telegrams.</code>text</p> Five Strokes <p><code>text Slice my plan into exactly five strokes: intention, terrain, rhythm, void, victory. Speak only in verbs.</code>text</p> High vs Floor <p><code>text Write the high-society summary first. Below it, the same info translated into shop-floor profanity.</code>text</p> Rewrite + Critique <pre><code>Rewrite my argument, then critique the rewrite, then critique the critique \ufffd?\\\" all in 3 nested texts.  \n</code></pre> Sharper Questions <pre><code>Unfold my vague question into a sequence of smaller, sharper questions; wait for my answer after each.  \n</code></pre> If It Failed <pre><code>If this proposal failed spectacularly, write the post-mortem headline, cause, and single Jira ticket that would have prevented it.  \n</code></pre> Micro\u2011Game <pre><code>Turn my problem into a tabletop micro-game: stats, win condition, random events. 1 page.  \n</code></pre> Golden Mean <pre><code>Give two parallel action plans: one Marcus Aurelius-stoic, one Go-with-the-Flow surfer. End with the hybrid \ufffd?~Golden Mean\ufffd?T step.\n</code></pre>"},{"location":"prompts/meta/context-reviewers-knitters/#tags","title":"Tags","text":""},{"location":"prompts/meta/context-reviewers-knitters/#meta-review-critique-iterative","title":"meta #review #critique #iterative","text":""},{"location":"prompts/meta/context-reviewers-knitters/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-27): Initial version.</li> </ul>"},{"location":"prompts/meta/explainers-reframers/","title":"Explainers / Reframers","text":""},{"location":"prompts/meta/explainers-reframers/#description","title":"Description","text":"<p>Prompts for reframing or compressing content in novel ways\ufffd?\"tweets, metaphors, debates, etc.</p>"},{"location":"prompts/meta/explainers-reframers/#how-to-use","title":"How to Use","text":"<ul> <li>Choose one pattern below and append it to your prompt.</li> <li>Keep the wording as\u2011is; only fill in the requested \u201cTopic\u201d/inputs.</li> <li>Run multiple patterns separately if you want clean outputs.</li> </ul>"},{"location":"prompts/meta/explainers-reframers/#prompts","title":"Prompts","text":"<p><pre><code>Compress this topic. Speak only in causal chains. Topic:  \nCompress this topic to a \ufffd%\\u000f 140-character tweet, a six-word story, and a single emoji. Topic:  \nExplain this concept at three metaphorical scales: \ufffd?oQuark\ufffd??, \ufffd?oEarth\ufffd??, \ufffd?oGalaxy\ufffd??. One paragraph each. Topic:  \nExplain this human custom to a silicon-based species with zero culture overlap, in toddler-level syntax. Topic:  \nModel this topic as a parliament of archetypes. Record a one-minute debate transcript, then the final vote. Topic:  \nBe the glitch in the matrix. Diagnose reality feature:  \n```text\n\n## Compact Views\n\n=== \"Tabs View\"\n\n==== \"Causal Chains\"\n```text\nCompress this topic. Speak only in causal chains. Topic:  \n```text\n\n==== \"Tweet/Story/Emoji\"\n```text\nCompress this topic to a \ufffd%\\u000f 140-character tweet, a six-word story, and a single emoji. Topic:  \n```text\n\n==== \"Metaphor Scales\"\n</code></pre> Explain this concept at three metaphorical scales: \ufffd?oQuark\ufffd??, \ufffd?oEarth\ufffd??, \ufffd?oGalaxy\ufffd??. One paragraph each. Topic: <pre><code>==== \"Alien Explanation\"\n</code></pre> Explain this human custom to a silicon-based species with zero culture overlap, in toddler-level syntax. Topic: <pre><code>==== \"Parliament Debate\"\n</code></pre> Model this topic as a parliament of archetypes. Record a one-minute debate transcript, then the final vote. Topic: <pre><code>==== \"Glitch in Matrix\"\n</code></pre> Be the glitch in the matrix. Diagnose reality feature: ```</p> Accordion View Causal Chains <p><code>text Compress this topic. Speak only in causal chains. Topic:</code>text</p> Tweet/Story/Emoji <p><code>text Compress this topic to a \ufffd%\\u000f 140-character tweet, a six-word story, and a single emoji. Topic:</code>text</p> Metaphor Scales <p><code>text Explain this concept at three metaphorical scales: \ufffd?oQuark\ufffd??, \ufffd?oEarth\ufffd??, \ufffd?oGalaxy\ufffd??. One paragraph each. Topic:</code>text</p> Alien Explanation <p><code>Explain this human custom to a silicon-based species with zero culture overlap, in toddler-level syntax. Topic:</code></p> Parliament Debate <p><code>Model this topic as a parliament of archetypes. Record a one-minute debate transcript, then the final vote. Topic:</code></p> Glitch in Matrix <p><code>Be the glitch in the matrix. Diagnose reality feature:</code></p>"},{"location":"prompts/meta/explainers-reframers/#tags","title":"Tags","text":""},{"location":"prompts/meta/explainers-reframers/#meta-explain-compress-reframe","title":"meta #explain #compress #reframe","text":""},{"location":"prompts/meta/explainers-reframers/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-27): Initial version.</li> </ul>"},{"location":"prompts/news-processing/1-fact-checking-news/","title":"Prompt Category or Prompt Name: Fact-Check News","text":""},{"location":"prompts/news-processing/1-fact-checking-news/#description","title":"Description","text":"<p>Fact-check the provided text via a step-by-step, iterative process that lets the assistant ask one question at a time to ensure maximum reliability.</p>"},{"location":"prompts/news-processing/1-fact-checking-news/#prompt","title":"Prompt","text":"<p>```text Here's some text inside brackets: [input the text here]. Task: You are tasked with fact-checking the provided text. Please follow the steps below and provide a detailed response. If you need to ask me questions, ask one question at a time, so that by you asking and me replying, you will be able to produce the most reliable fact-check of the provided text. Here are the steps you should follow: 1. Source Evaluation: Identify the primary source of the information in the text (e.g., author, speaker, publication, or website). Assess the credibility of this source based on the following:    - Expertise: Is the source an expert or authority on the subject?    - Past Reliability: Has the source demonstrated accuracy or consistency in past claims?    - Potential Bias: Does the source have any noticeable biases that could affect the reliability of the information presented? 2. Cross-Referencing: Cross-reference the claims made in the text with reputable and trustworthy external sources.    - Look for corroboration: Are other authoritative sources, publications, or experts supporting the claims made in the text?    - Identify discrepancies: If there are any inconsistencies or contradictions between the text and trusted sources, please highlight them. 3. Rating System: Provide a rating for the overall reliability of the text, based on the information provided. Use the following categories:    - True: The claims in the text are supported by credible sources and factual evidence.    - Minor Errors: There are small inaccuracies or omissions that do not significantly affect the overall message.    - Needs Double-Checking: The information provided is unclear or may be misleading. Further verification is needed for key claims.    - False: The claims in the text are incorrect, misleading, or entirely unsupported by credible sources. 4. Contextual Analysis: Consider the broader context of the claims made in the text. Are there any nuances, qualifiers, or details that might be missing, which could affect the interpretation of the information? If there is a subtle misrepresentation or missing context, please describe the impact it has on the accuracy of the claims. 5. Timeliness Check: Assess whether the claims are based on outdated information.    - Is the information current?: Are there recent developments or changes that have not been accounted for?    - If the information is outdated, indicate how this affects the validity of the text\u2019s claims. 6. Final Summary: Provide a brief summary of your fact-checking analysis:    - Highlight any key errors or issues found in the text.    - Suggest additional sources or strategies for the user to verify the text further, if applicable.    - Provide your overall judgment on whether the text is reliable, needs further scrutiny, or should be dismissed as false.</p> <p>My original post has interesting comments on how to optimize this prompt, here. ```text</p>"},{"location":"prompts/news-processing/1-fact-checking-news/#tags","title":"Tags","text":""},{"location":"prompts/news-processing/1-fact-checking-news/#news-fact-check-verification","title":"news #fact-check #verification","text":""},{"location":"prompts/news-processing/1-fact-checking-news/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-28): Initial version.</li> </ul>"},{"location":"prompts/news-processing/2-evaluate-interventions/","title":"Prompt Category or Prompt Name: Evaluate Government Interventions","text":""},{"location":"prompts/news-processing/2-evaluate-interventions/#description","title":"Description","text":"<p>Evaluate the adequacy of described government interventions by examining demographics, expert studies, and historical data.</p>"},{"location":"prompts/news-processing/2-evaluate-interventions/#prompt","title":"Prompt","text":"<p>```text The following text inside brackets discusses various government interventions: [input a text here describing the government intervention(s) whose adequacy you want to evaluate]. Please analyze the effectiveness of these interventions by evaluating the following elements: 1. Demographic Statistics: How do the government\u2019s actions align with the statistical trends related to the issue? Are the interventions targeting the correct areas based on available data (e.g., birth rates, poverty levels, etc.)? 2. Expert Studies: How do the expert opinions or studies mentioned in the text reflect on the adequacy of the interventions? Are experts suggesting that these efforts are sufficient, or do they propose alternative solutions? 3. Historical Data: How does the historical context of the issue influence the assessment of the government\u2019s interventions? Is there evidence that similar past efforts have been successful or failed, and how does that shape the current intervention's likelihood of success?</p> <p>Using these knowledge-generating principles, please provide a comprehensive evaluation of the government\u2019s actions in relation to the data, expert analysis, and history.</p> <p>```text</p>"},{"location":"prompts/news-processing/2-evaluate-interventions/#tags","title":"Tags","text":""},{"location":"prompts/news-processing/2-evaluate-interventions/#news-evaluation-policy-analysis","title":"news #evaluation #policy-analysis","text":""},{"location":"prompts/news-processing/2-evaluate-interventions/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-28): Initial version.</li> </ul>"},{"location":"prompts/news-processing/3-act-on-news/","title":"Prompt Category or Name: Act on News","text":""},{"location":"prompts/news-processing/3-act-on-news/#description","title":"Description","text":"<p>Turn a news story into a personalized, actionable checklist\u2014iteratively refined via Q&amp;A.</p>"},{"location":"prompts/news-processing/3-act-on-news/#prompt","title":"Prompt","text":"<p>```text Here's a text: \u201c[paste the news story here]\u201d Based on this text, create one simple, actionable checklist; the goal is to create a checklist that is easy to follow and provide actionable steps. Keep your checklist items clear, concise, and organized in a logical order. Use Bullet Points: This makes the checklist easy to read. Focus on Actionable Items: For example, instead of \u201cEnsure data privacy compliance,\u201d specify, \u201cReview data collection practices for GDPR compliance, including consent forms and data retention policies.\u201d Group Items by Categories: Organize the checklist by stages or areas (e.g., \"Data Collection,\" \"Data Storage,\" \"Data Sharing\" for GDPR compliance). Use that checklist to help me use it for my very personal situation. If you need to ask me questions, then ask me one question at a time, so that you asking and me replying, you can end up with a simple plan for me.</p> <p>If you submit this prompt and the AI only replies with a checklist, without any question, then simply reply back with the last two sentences of the prompt:</p> <p>Use that checklist to help me use it for my very personal situation. If you need to ask me questions, then ask me one question at a time, so that you asking and me replying, you can end up with a simple plan for me.</p> <p>```text</p>"},{"location":"prompts/news-processing/3-act-on-news/#tags","title":"Tags","text":""},{"location":"prompts/news-processing/3-act-on-news/#news-action-plan-checklist","title":"news #action-plan #checklist","text":""},{"location":"prompts/news-processing/3-act-on-news/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-28): Initial version.</li> </ul>"},{"location":"prompts/templates/generic-template/","title":"","text":""},{"location":"prompts/templates/generic-template/#description","title":"Description","text":"<p>[What this prompt is for and any context]</p>"},{"location":"prompts/templates/generic-template/#prompt","title":"Prompt","text":"<pre><code>&lt;Your prompt text here&gt;\n</code></pre>"},{"location":"prompts/templates/generic-template/#tags","title":"Tags","text":""},{"location":"prompts/templates/generic-template/#tag1-tag2","title":"tag1 #tag2","text":""},{"location":"prompts/templates/generic-template/#version-history","title":"Version History","text":"<ul> <li>v1.0 (YYYY-MM-DD): Initial version.</li> </ul>"}]}