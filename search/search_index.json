{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"prompt-hub","text":"<p>An MIT-licensed hub for high-quality LLM prompts and AI learning resources.</p>"},{"location":"#structure","title":"Structure","text":"<ul> <li><code>prompts/</code> - live prompts by category</li> <li><code>learning/</code> - reading lists, notes, cheatsheets, roadmaps, glossary</li> <li><code>templates/</code> - shared templates for learning content</li> <li><code>CHANGELOG.md</code> - history of changes</li> <li><code>LICENSE</code> - MIT license</li> </ul>"},{"location":"#getting-started","title":"Getting started","text":"<ul> <li>Prompts: browse <code>prompts/</code> (e.g., <code>prompts/prompt-booster.md</code>).</li> <li>Learning: start at <code>learning/README.md</code> - jump to the LLM Systems reading list or the LLM Roadmap.</li> </ul>"},{"location":"#index-generation","title":"Index generation","text":"<ul> <li>Build topic index: <code>powershell -ExecutionPolicy Bypass -File scripts/generate-topic-index.ps1</code></li> <li>Output file: <code>learning/topics.md</code></li> </ul>"},{"location":"#docs-site","title":"Docs site","text":"<ul> <li>Preview locally: <code>pip install mkdocs mkdocs-material</code> then <code>mkdocs serve</code> (opens http://127.0.0.1:8000)</li> <li>Build static site: <code>mkdocs build</code> (outputs to <code>site/</code>)</li> <li>Optional deploy to GitHub Pages: <code>mkdocs gh-deploy</code></li> <li>Config file: <code>mkdocs.yml</code> (sources live under <code>docs/</code>)</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<p>Prompts 1. Add or update a <code>.md</code> in <code>prompts/&lt;category&gt;/</code>. 2. Keep titles clear and include tags. 3. Update <code>CHANGELOG.md</code>.</p> <p>Learning content 1. Choose a type: <code>learning/(reading-lists|notes|cheatsheets|roadmaps|papers|courses)</code>. 2. Start from a template in <code>templates/</code> and include YAML front matter (<code>title</code>, <code>summary</code>, <code>type</code>, <code>level</code>, <code>topics</code>, <code>updated</code>). 3. Prefer concise commentary over raw link dumps. 4. Update <code>learning/README.md</code> if you add a new major topic.</p>"},{"location":"#contributing-developing","title":"Contributing &amp; Developing","text":"<ul> <li>See Contributing for how to add/update content.</li> <li>See Developing for local dev, CI, and deploy details.</li> </ul>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this repository are tracked here.</p>"},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>Created <code>prompts/meta/</code> folder.</li> <li>Added <code>prompts/meta/behavior-changers.md</code> with <code># Category: Behavior Changers</code>.</li> <li>Added <code>prompts/meta/explainers-reframers.md</code> with <code># Category: Explainers / Reframers</code>.</li> <li>Added <code>prompts/meta/context-reviewers-knitters.md</code> with <code># Category: Context Reviewers / Knitters</code>.</li> </ul>"},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Updated generic prompt template in <code>prompts/templates/generic-template.md</code>: changed heading from <code># Prompt:</code> to <code># Category:</code>.</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing","text":"<p>Thanks for improving Prompt\u2011Hub! This guide lists the essentials for contributing content.</p>"},{"location":"CONTRIBUTING/#quick-checklist","title":"Quick Checklist","text":"<ul> <li>Edit files under <code>docs/</code> only \u2014 never <code>gh-pages</code>.</li> <li>Keep pages short, clear, and useful; avoid link dumps.</li> <li>Add YAML front matter at the top:</li> </ul> <pre><code>---\ntitle: \"Page Title\"\nsummary: \"One\u2011line why it matters\"\ntype: reading-list|note|cheatsheet|roadmap\nlevel: beginner|intermediate|advanced\ntopics: [llms, evals]\nupdated: YYYY-MM-DD\nsee_also:\n  - ./relative/link.md\n---\n</code></pre> <ul> <li>Use relative links (e.g., <code>reading-lists/llm-systems.md</code>).</li> <li>Use fenced code blocks (```) so copy buttons appear.</li> <li>For tabs/accordions, follow Material syntax (see Developing).</li> </ul>"},{"location":"CONTRIBUTING/#add-a-new-page","title":"Add a New Page","text":"<p>1) Create the file under <code>docs/\u2026</code></p> <p>2) Add front matter (see above)</p> <p>3) (Optional) Add to sidebar nav: edit <code>mkdocs.yml</code> \u2192 <code>nav:</code></p> <p>4) (Optional) Update topics index:</p> <pre><code>powershell -ExecutionPolicy Bypass -File scripts/generate-topic-index.ps1\n</code></pre> <p>5) Preview locally:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"CONTRIBUTING/#submitting-a-change","title":"Submitting a Change","text":"<ul> <li>Open a Pull Request to <code>main</code>.</li> <li>CI checks must pass:</li> <li>Strict MkDocs build</li> <li>Link check on Markdown sources</li> <li>After merge to <code>main</code>, the site is deployed automatically to GitHub Pages.</li> </ul>"},{"location":"CONTRIBUTING/#style-notes","title":"Style Notes","text":"<ul> <li>Prefer concise bullets and short paragraphs.</li> <li>Use meaningful section headers.</li> <li>Prefer en/em dashes (\u2013/\u2014) over hyphen spam where appropriate.</li> <li>Keep link text descriptive (not \u201chere\u201d).</li> </ul>"},{"location":"DEVELOPING/","title":"Developing","text":"<p>This repo publishes a MkDocs + Material site from the <code>docs/</code> folder to GitHub Pages (<code>gh-pages</code> branch). This guide covers local setup, structure, CI, deploys, and conventions.</p>"},{"location":"DEVELOPING/#source-layout","title":"Source Layout","text":"<ul> <li><code>docs/</code> \u2014 all site content and assets</li> <li><code>learning/</code> \u2014 reading\u2011lists, notes, cheatsheets, roadmaps, glossary</li> <li><code>prompts/</code> \u2014 prompt pages (some with tabs/accordions, copy buttons)</li> <li><code>styles/overrides.css</code> \u2014 site CSS overrides (copy button visibility, wrap styles)</li> <li><code>assets/wrap-toggle.js</code> \u2014 global \u201cWrap\u201d toggle (line\u2011wrap for code blocks)</li> <li><code>README.md</code> \u2014 site home (appears as Home)</li> <li><code>CHANGELOG.md</code> \u2014 changelog page</li> <li><code>mkdocs.yml</code> \u2014 site config + nav</li> <li><code>scripts/generate-topic-index.ps1</code> \u2014 generates <code>docs/learning/topics.md</code></li> </ul>"},{"location":"DEVELOPING/#local-development","title":"Local Development","text":"<p>Prereqs: Python 3.11+ recommended.</p> <pre><code>pip install mkdocs mkdocs-material\n</code></pre> <p>Run locally:</p> <pre><code>mkdocs serve\n</code></pre> <p>Build locally:</p> <pre><code>mkdocs build\n</code></pre> <p>Regenerate topics index (optional):</p> <pre><code>powershell -ExecutionPolicy Bypass -File scripts/generate-topic-index.ps1\n</code></pre>"},{"location":"DEVELOPING/#ci-and-deploys","title":"CI and Deploys","text":"<ul> <li>Workflow: <code>.github/workflows/deploy-docs.yml</code></li> <li>On PR \u2192 <code>docs-checks</code> job runs:<ul> <li>Install deps from <code>requirements-docs.txt</code></li> <li>Strict build: <code>mkdocs build --strict</code></li> <li>Link check (Lychee) against <code>docs/**/*.md</code> with <code>lychee.toml</code></li> </ul> </li> <li>On push to <code>main</code> \u2192 <code>docs-checks</code> then <code>deploy-docs</code> publishes <code>site/</code> to <code>gh-pages</code>.</li> <li>Pip caching enabled for faster runs.</li> </ul> <p>Branch protection (recommended):</p> <ul> <li>Settings \u2192 Branches \u2192 Protect <code>main</code> with required status checks:</li> <li>\u201cDocs Checks (build + links)\u201d must pass</li> <li>Optionally require branch up to date before merging</li> </ul> <p>Do not edit <code>gh-pages</code> directly \u2014 it is an artifact branch and will be overwritten by deploys.</p>"},{"location":"DEVELOPING/#authoring-guidelines","title":"Authoring Guidelines","text":"<ul> <li>Front matter (YAML) at top of each page:</li> <li><code>title</code>, <code>summary</code>, <code>type</code>, <code>level</code>, <code>topics: [a, b]</code>, <code>updated</code>, optional <code>see_also</code></li> <li>Links: use relative links within <code>docs/</code> when possible.</li> <li>Tabs/Accordions (Material):</li> <li>Tabs: <code>=== \"Tab Title\"</code> with indented fenced content under each tab</li> <li>Accordions: <code>??? note \"Title\"</code> with indented fenced blocks</li> <li>Code blocks:</li> <li>Use fenced blocks (```) so copy buttons appear.</li> <li>Global Wrap toggle in header controls line\u2011wrapping.</li> </ul>"},{"location":"DEVELOPING/#navigation","title":"Navigation","text":"<p>Edit <code>mkdocs.yml</code> \u2192 <code>nav:</code> to add pages to the sidebar. Files not in <code>nav</code> are still built (and searchable) but won\u2019t appear in the sidebar.</p>"},{"location":"DEVELOPING/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Build fails in CI (strict):</li> <li>Check <code>mkdocs.yml</code> syntax and missing files in <code>nav</code> entries</li> <li>Fix malformed Markdown (unclosed fences, invalid tab nesting)</li> <li>Link checker (Lychee) fails:</li> <li>See <code>lychee.toml</code> for excludes/accepted codes (e.g., LinkedIn and 429s)</li> <li>Prefer https URLs and update moved links</li> </ul>"},{"location":"learning/","title":"Learning Hub","text":"<p>This area hosts AI learning resources: curated reading lists, concise notes, cheatsheets, roadmaps, paper notes, and course notes. Everything uses lightweight YAML front matter for tagging and indexing.</p>"},{"location":"learning/#quick-links","title":"Quick links","text":"<ul> <li>Reading list: LLM Systems</li> <li>Notes: Transformer Intuition</li> <li>Cheatsheet: Retrieval + RAG Evaluation</li> <li>Roadmap: LLM Roadmap</li> <li>Glossary: Glossary</li> </ul>"},{"location":"learning/#organization","title":"Organization","text":"<ul> <li><code>reading-lists/</code> \u2014 curated lists with short commentary</li> <li><code>notes/</code> \u2014 concept summaries and deep dives</li> <li><code>cheatsheets/</code> \u2014 quick, practical references</li> <li><code>roadmaps/</code> \u2014 step-by-step pathways through topics</li> <li><code>papers/</code> \u2014 paper summaries with key takeaways</li> <li><code>courses/</code> \u2014 course notes and exercises</li> <li><code>glossary.md</code> \u2014 concise definitions</li> </ul>"},{"location":"learning/#conventions","title":"Conventions","text":"<ul> <li>Every file starts with YAML front matter: <code>title</code>, <code>summary</code>, <code>type</code>, <code>level</code>, <code>topics</code>, <code>updated</code>, <code>see_also</code>.</li> <li>Use lowercase-hyphenated filenames (e.g., <code>agents-reading-list.md</code>).</li> <li>Keep curated lists focused; include 1\u20132 line commentary per link.</li> <li>For now, write <code>topics</code> as a single-line bracket list (e.g., <code>topics: [llms, evals]</code>) so the index script can parse it.</li> </ul>"},{"location":"learning/glossary/","title":"Glossary","text":"<ul> <li>LLM: Large Language Model trained to predict next tokens.</li> <li>Token: A chunk of text the model processes; not always a word.</li> <li>Context window: Max tokens the model can attend to at once.</li> <li>Embedding: Vector representation of text for similarity search.</li> <li>Temperature: Controls randomness; higher = more diverse outputs.</li> <li>Top-p (nucleus): Samples from top cumulative probability mass.</li> <li>RAG: Retrieval-Augmented Generation; uses external docs at inference.</li> <li>Hallucination: Confident but unsupported or incorrect output.</li> </ul>"},{"location":"learning/topics/","title":"Topics Index (auto-generated)","text":"<p>Generated: 2025-10-26 19:59 +02:00</p> <p>Do not edit by hand; run ./scripts/generate-topic-index.ps1.</p>"},{"location":"learning/topics/#agents","title":"agents","text":"<ul> <li>LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems.</li> </ul>"},{"location":"learning/topics/#ai","title":"ai","text":"<ul> <li>AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.</li> <li>AI Training &amp; Certifications - reading-list, intermediate - Curated training paths and certifications suitable for a senior solutions architect with prior AI experience.</li> </ul>"},{"location":"learning/topics/#business","title":"business","text":"<ul> <li>AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.</li> </ul>"},{"location":"learning/topics/#certification","title":"certification","text":"<ul> <li>AI Training &amp; Certifications - reading-list, intermediate - Curated training paths and certifications suitable for a senior solutions architect with prior AI experience.</li> </ul>"},{"location":"learning/topics/#evals","title":"evals","text":"<ul> <li>LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems.</li> <li>Retrieval + RAG Evaluation Cheatsheet - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness.</li> </ul>"},{"location":"learning/topics/#glossary","title":"glossary","text":"<ul> <li>Glossary - note, beginner - Concise definitions for common LLM terms.</li> </ul>"},{"location":"learning/topics/#leadership","title":"leadership","text":"<ul> <li>AI Training &amp; Certifications - reading-list, intermediate - Curated training paths and certifications suitable for a senior solutions architect with prior AI experience.</li> </ul>"},{"location":"learning/topics/#learning","title":"learning","text":"<ul> <li>AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.</li> <li>AI Training &amp; Certifications - reading-list, intermediate - Curated training paths and certifications suitable for a senior solutions architect with prior AI experience.</li> </ul>"},{"location":"learning/topics/#llms","title":"llms","text":"<ul> <li>LLM Roadmap - roadmap, beginner - A pragmatic path from foundations to systems.</li> <li>LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems.</li> <li>Transformer Intuition - note, intermediate - Why attention helps and how stacking layers builds understanding.</li> </ul>"},{"location":"learning/topics/#productivity","title":"productivity","text":"<ul> <li>AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.</li> </ul>"},{"location":"learning/topics/#rag","title":"rag","text":"<ul> <li>LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems.</li> <li>Retrieval + RAG Evaluation Cheatsheet - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness.</li> </ul>"},{"location":"learning/topics/#retrieval","title":"retrieval","text":"<ul> <li>Retrieval + RAG Evaluation Cheatsheet - cheatsheet, intermediate - Quick metrics and practices for retrieval quality and answer correctness.</li> </ul>"},{"location":"learning/topics/#roadmap","title":"roadmap","text":"<ul> <li>LLM Roadmap - roadmap, beginner - A pragmatic path from foundations to systems.</li> </ul>"},{"location":"learning/topics/#systems","title":"systems","text":"<ul> <li>LLM Systems: Curated Overview - reading-list, intermediate - High-signal resources for understanding and building LLM systems.</li> </ul>"},{"location":"learning/topics/#transformers","title":"transformers","text":"<ul> <li>Transformer Intuition - note, intermediate - Why attention helps and how stacking layers builds understanding.</li> </ul>"},{"location":"learning/topics/#youtube","title":"youtube","text":"<ul> <li>AI Learning: Creators and Channels - reading-list, beginner - Curated creators covering AI fundamentals, tooling, productivity, and business impact.</li> </ul>"},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/","title":"Retrieval + RAG Evaluation Cheatsheet","text":""},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/#retrieval-metrics","title":"Retrieval metrics","text":"<ul> <li>Recall@k: Fraction of queries with a relevant item in top-k (coverage).</li> <li>Precision@k: Fraction of top-k that are relevant (purity).</li> <li>MRR: Mean reciprocal rank of first relevant hit (position-sensitive).</li> <li>nDCG: Position-weighted gain for multiple relevant items.</li> </ul>"},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/#rag-answer-metrics","title":"RAG answer metrics","text":"<ul> <li>Faithfulness: Is the answer supported by provided sources?</li> <li>Correctness: Does it answer the question fully and accurately?</li> <li>Grounding: Are citations present and relevant?</li> </ul>"},{"location":"learning/cheatsheets/retrieval-evals-cheatsheet/#practical-tips","title":"Practical tips","text":"<ul> <li>Chunking: Balance chunk size vs overlap; test on your domain text.</li> <li>Indexing: Use embeddings suited to your content (code vs prose, multilingual).</li> <li>Re-ranking: Apply cross-encoder re-rankers for higher precision at low k.</li> <li>Negative sampling: Hard negatives improve retriever discrimination.</li> <li>Eval set: Build a representative, diverse set; avoid leakage from docs.</li> </ul>"},{"location":"learning/notes/transformers-intuition/","title":"Transformer Intuition","text":""},{"location":"learning/notes/transformers-intuition/#big-picture","title":"Big picture","text":"<p>Transformers replace recurrence with attention: each token selectively attends to others to build context-aware representations. Stacking attention + feed-forward blocks lets the model compose higher-level features.</p>"},{"location":"learning/notes/transformers-intuition/#core-pieces","title":"Core pieces","text":"<ul> <li>Self-attention: Queries/Keys/Values produce weighted mixtures of token features.</li> <li>Multi-head: Parallel attention subspaces capture different relations (syntax, long-range cues, etc.).</li> <li>Positional info: Encodings inject order so attention knows where tokens sit.</li> <li>Residual + normalization: Enable deep stacks and stable training.</li> <li>Pretraining objective: Predict masked or next tokens \u2192 learn distribution of text.</li> </ul>"},{"location":"learning/notes/transformers-intuition/#why-it-works","title":"Why it works","text":"<ul> <li>Content-based routing: Tokens pull exactly the context they need.</li> <li>Parallelism: No sequential dependency \u2192 efficient training and longer-range reasoning.</li> <li>Compositionality: Layers iteratively refine representations.</li> </ul>"},{"location":"learning/notes/transformers-intuition/#pitfalls","title":"Pitfalls","text":"<ul> <li>Context window limits: Truncation and poor chunking hurt results.</li> <li>Spurious cues: Models may overfit patterns; prefer careful evals and ablations.</li> <li>Hallucinations: Add retrieval or constraints when faithfulness matters.</li> </ul>"},{"location":"learning/notes/transformers-intuition/#see-also","title":"See also","text":"<ul> <li>Reading list: ../reading-lists/llm-systems.md</li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/","title":"AI Learning: Creators and Channels","text":"<p>Short, opinionated list with why\u2011it\u2011matters notes. Focused on applied, architecture, and strategy angles rather than hype.</p>"},{"location":"learning/reading-lists/ai-creators-and-channels/#foundations","title":"Foundations","text":"<ul> <li>Khan Academy - Clear math/programming refreshers that support ML/AI study.   YouTube: https://www.youtube.com/khanacademy   Site: https://www.khanacademy.org</li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#technical-deep-dives-research","title":"Technical Deep Dives &amp; Research","text":"<ul> <li> <p>Andrej Karpathy \u2014 First\u2011principles LLM/NN explainers and deep dives (e.g., Zero\u2011to\u2011Hero).   YouTube: https://www.youtube.com/@AndrejKarpathy   Site: https://karpathy.ai   Why it matters: bridges research and implementation so architects can reason about model behavior.</p> </li> <li> <p>Two Minute Papers \u2014 Visual explainers of the latest AI research papers.   YouTube: https://www.youtube.com/user/keeroyz   Why it matters: fast way to track where capabilities are headed and brief stakeholders.</p> </li> <li> <p>3Blue1Brown \u2014 Mathematical intuition for deep learning and neural nets.   YouTube: https://www.youtube.com/c/3blue1brown   Site: https://www.3blue1brown.com   Why it matters: strengthens fundamentals for evaluating trade\u2011offs and feasibility.</p> </li> <li> <p>Yannic Kilcher \u2014 In\u2011depth walkthroughs of state\u2011of\u2011the\u2011art ML papers.   YouTube: https://www.youtube.com/@YannicKilcher   Site: https://www.ykilcher.com   Why it matters: helps anticipate what may become production\u2011ready in 12\u201318 months.</p> </li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#engineering-builders","title":"Engineering / Builders","text":"<ul> <li> <p>Sabrina Ramonov - Practical coding/AI content and dev workflows.   YouTube: https://www.youtube.com/@sabrina_ramonov   Site: https://www.sabrina.dev</p> </li> <li> <p>Sentdex \u2014 Practical Python + ML projects from scratch.   YouTube: https://www.youtube.com/@sentdex   Why it matters: shows real implementation constraints beyond demos.</p> </li> <li> <p>Sam Witteveen \u2014 Hands\u2011on transformer/LLM and agent patterns (GDE, ML).   YouTube: https://www.youtube.com/@samwitteveenai   Why it matters: concrete patterns for production apps and multi\u2011agent systems.</p> </li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#applied-business-productivity","title":"Applied, Business, Productivity","text":"<ul> <li> <p>Alex Hormozi - Strategy and operations; useful for framing AI product and GTM decisions.   YouTube: https://www.youtube.com/c/AlexHormozi</p> </li> <li> <p>Ali Abdaal \u2014 Productivity systems; frequent AI tool coverage and practical workflows.   YouTube: https://www.youtube.com/c/aliabdaal   Site: https://aliabdaal.com</p> </li> <li> <p>Codie Sanchez \u2014 Business ideas and automations; occasional AI leverage in small biz.   YouTube: https://www.youtube.com/@CodieSanchezCT</p> </li> <li> <p>Graham Stephan \u2014 Economics/finance perspective; helpful for macro context of AI\u2019s impact.   YouTube: https://www.youtube.com/channel/UCUaT_39o1x6qWjz7K2pWcgw</p> </li> <li> <p>Leon Motley \u2014 AI productivity and tooling; bite\u2011sized demos.   YouTube: https://www.youtube.com/@leomotley</p> </li> <li> <p>Robo Nuggets - Short, practical AI tips and experiments.   YouTube: https://www.youtube.com/@RoboNuggets</p> </li> <li> <p>AI Explained \u2014 High\u2011signal analysis of new models and research.   YouTube: https://www.youtube.com/@aiexplained-official   Why it matters: helps assess capabilities/limitations when picking vendors.</p> </li> <li> <p>Matthew Berman \u2014 Tests major AI releases with hands\u2011on demos.   YouTube: https://www.youtube.com/@matthew_berman   Site: https://forwardfuture.ai   Why it matters: rapid evaluations to inform tool selection.</p> </li> <li> <p>Matt Wolfe \u2014 Weekly news + curated database of AI tools.   YouTube: https://www.youtube.com/@mreflow   Site: https://futuretools.io   Why it matters: saves time scouting options for specific use cases.</p> </li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#strategic-architecture-level-thinking","title":"Strategic / Architecture-Level Thinking","text":"<ul> <li> <p>Jordan Harrod - Explains AI, ML, and neuroscience with emphasis on ethics and clarity.   YouTube: https://www.youtube.com/@jordanharrod   Site: https://www.jordanharrod.com   Why it matters: adds scientific and ethical depth useful for system-level decisions.</p> </li> <li> <p>GOTO Conferences - Real-world engineering and architecture talks from senior practitioners.   YouTube: https://www.youtube.com/@GOTOConferences   Why it matters: trade-off thinking for scalable architectures and applied AI adoption.</p> </li> <li> <p>David Shapiro \u2014 AI\u2019s business and societal implications (exec\u2011level framing).   YouTube: https://www.youtube.com/@DaveShap   Site: https://www.daveshap.io   Why it matters: equips architects for C\u2011suite conversations on transformation.</p> </li> <li> <p>Go Cloud Architects \u2014 Enterprise/cloud architecture with AI transformation.   YouTube: https://www.youtube.com/@gocloudarchitects   Why it matters: patterns to align AI initiatives with business outcomes.</p> </li> <li> <p>Anthropic - Behind-the-scenes look at Claude and AI safety research.   YouTube: https://www.youtube.com/@AnthropicAI   Site: https://www.anthropic.com   Why it matters: understand foundation model behavior and API-level design choices.</p> </li> <li> <p>OpenAI - Product updates, research talks, and LLM deep dives.   YouTube: https://www.youtube.com/@OpenAI   Site: https://openai.com/research   Why it matters: helps you architect with (or around) leading model platforms.</p> </li> <li> <p>HiveMQ - Industrial/IoT integrations and AI-driven digital transformation.   YouTube: https://www.youtube.com/@HiveMQ   Site: https://www.hivemq.com   Why it matters: useful if you handle edge data, event streaming, or system interoperability.</p> </li> <li> <p>Lex Fridman \u2014 Long\u2011form conversations with AI leaders (2\u20135h).   YouTube: https://www.youtube.com/@lexfridman   Site: https://lexfridman.com   Why it matters: strategic insight into where AI is going from the people steering it.</p> </li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#ai-agents-automation","title":"AI Agents &amp; Automation","text":"<ul> <li> <p>AI Jason \u2014 Production\u2011ready agent workflows and architectures.   YouTube: https://www.youtube.com/@AIJasonZ   Site: https://www.ai-jason.com   Why it matters: concrete designs for agentic applications and coding\u2011assistant setups.</p> </li> <li> <p>Prompt Engineering (GDE) \u2014 Deep dives on RAG and prompt/LLM application patterns.   YouTube: https://www.youtube.com/@engineerprompt   Site: https://engineerprompt.ai   Why it matters: patterns for robust retrieval and prompt design in production systems.</p> </li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#emerging-voices-to-monitor","title":"Emerging Voices (to monitor)","text":"<ul> <li>Nate Herk - Business automation and AI systems (channel names vary, search latest).  </li> <li>Brent Melinowski - Practical AI/business automation content (verify latest channel).</li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#bigpicture-inspiration","title":"Big\u2011Picture / Inspiration","text":"<ul> <li>TED \u2014 Curated short talks on technology, ethics, and design thinking.   YouTube: https://www.youtube.com/user/TEDtalksDirector   Site: https://www.ted.com</li> </ul>"},{"location":"learning/reading-lists/ai-creators-and-channels/#notes-for-senior-solutions-architects","title":"Notes for Senior Solutions Architects","text":"<ul> <li>Combine GOTO Conferences, Anthropic, and HiveMQ for enterprise/architecture insights.  </li> <li>Use Sabrina Ramonov and Robo Nuggets for quick \u201chow\u2011it\u2011works\u201d reference points.  </li> <li>Follow Jordan Harrod and Ali Abdaal to bridge conceptual understanding with practical workflows.  </li> <li>Revisit Khan Academy to refresh foundational math/programming when deepening ML study.</li> </ul>"},{"location":"learning/reading-lists/llm-systems/","title":"LLM Systems: Curated Overview","text":"<p>Quality bar: this list stays short and opinionated. Each link includes a why-it-matters note.</p>"},{"location":"learning/reading-lists/llm-systems/#foundations-transformers-attention","title":"Foundations (Transformers + Attention)","text":"<ul> <li>The Illustrated Transformer \u2014 Clear visuals for attention and the encoder\u2013decoder stack. https://jalammar.github.io/illustrated-transformer/</li> <li>Attention Is All You Need (Vaswani et al., 2017) \u2014 The original Transformer paper; skim for architecture, read for intuition. https://arxiv.org/abs/1706.03762</li> </ul>"},{"location":"learning/reading-lists/llm-systems/#prompting-patterns","title":"Prompting + Patterns","text":"<ul> <li>OpenAI Cookbook \u2014 Practical prompting patterns, evaluation ideas, and tooling. https://github.com/openai/openai-cookbook</li> <li>Prompt engineering patterns (assorted guides) \u2014 Use chain-of-thought, self-consistency, and structured outputs judiciously; measure impact, don\u2019t assume.</li> </ul>"},{"location":"learning/reading-lists/llm-systems/#rag-retrieval-augmented-generation","title":"RAG (Retrieval-Augmented Generation)","text":"<ul> <li>Retrieval-Augmented Generation for Knowledge-Intensive NLP (Lewis et al., 2020) \u2014 The core idea and trade-offs. https://arxiv.org/abs/2005.11401</li> <li>Vector databases (docs) \u2014 Focus on indexing choices, chunking strategies, and evaluation with domain text.</li> </ul>"},{"location":"learning/reading-lists/llm-systems/#evaluation","title":"Evaluation","text":"<ul> <li>IR metrics primer \u2014 Precision/Recall@k, MRR, nDCG; know how they respond to re-ranking and chunking.</li> <li>Task-specific evals \u2014 Measure faithfulness, answer correctness, and source attribution; prefer automatic + spot human audit.</li> </ul>"},{"location":"learning/reading-lists/llm-systems/#agents-tool-use","title":"Agents + Tool Use","text":"<ul> <li>Keep it simple first \u2014 Tool calling adds latency and failure modes; add only with clear ROI and guardrails.</li> <li>Monitoring + fallback \u2014 Log tool inputs/outputs, timeouts, and define safe fallbacks.</li> </ul>"},{"location":"learning/reading-lists/llm-systems/#systems-design","title":"Systems Design","text":"<ul> <li>Start with evals \u2014 Define success metrics before scaling complexity.</li> <li>Observability \u2014 Capture prompts, versions, inputs, outputs, and model metadata for reproducibility.</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/","title":"AI Training & Certifications","text":""},{"location":"learning/reading-lists/training-and-certifications/#ai-training-and-certification-overview","title":"AI Training and Certification Overview","text":""},{"location":"learning/reading-lists/training-and-certifications/#for-a-senior-solutions-architect-with-prior-ai-experience","title":"For a Senior Solutions Architect with Prior AI Experience","text":""},{"location":"learning/reading-lists/training-and-certifications/#most-relevant-from-the-initial-list","title":"\u2705 Most Relevant from the Initial List","text":""},{"location":"learning/reading-lists/training-and-certifications/#1-ai-for-organizational-leaders-microsoft-linkedin","title":"1. AI for Organizational Leaders (Microsoft &amp; LinkedIn)","text":"<ul> <li>Leadership-level training focused on AI adoption, governance, and scaling across organizations.  </li> <li>Target audience: technical leads, architects, and executives implementing AI strategy.  </li> <li>Link: https://www.linkedin.com/learning/paths/ai-for-organizational-leaders-by-microsoft-and-linkedin</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#2-generative-ai-leader-google-cloud-skills-boost-path-1951","title":"2. Generative AI Leader (Google Cloud Skills Boost \u2013 Path 1951)","text":"<ul> <li>Advanced path covering generative AI concepts, prompt engineering, foundation models, and Google Cloud's AI suite (Gemini, Vertex, AI Studio).  </li> <li>Offers practical, hands-on labs and completion badge.  </li> <li>Link: https://www.cloudskillsboost.google/paths/1951</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#3-human-skills-in-the-age-of-ai-microsoft-linkedin","title":"3. Human Skills in the Age of AI (Microsoft &amp; LinkedIn)","text":"<ul> <li>Focuses on communication, adaptability, and critical thinking in AI-driven teams.  </li> <li>Complements technical expertise with leadership soft skills.  </li> <li>Link: https://www.linkedin.com/learning/paths/human-skills-in-the-age-of-ai-by-microsoft-and-linkedin</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#possibly-useful-for-broader-context","title":"\u26aa Possibly Useful for Broader Context","text":""},{"location":"learning/reading-lists/training-and-certifications/#4-umd-rh-smith-executive-education-free-certificate-in-ai-and-career-empowerment","title":"4. UMD RH Smith Executive Education \u2013 Free Certificate in AI and Career Empowerment","text":"<ul> <li>Strategic-level program emphasizing how professionals can apply AI to enhance career growth and productivity.  </li> <li>Suitable for leaders seeking business applications rather than coding practice.  </li> <li>Link: https://rhsmith.umd.edu/programs/executive-education/learning-opportunities-individuals/free-online-certificate-artificial-intelligence-and-career-empowerment</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#5-career-essentials-in-generative-ai-by-microsoft-and-linkedin","title":"5. Career Essentials in Generative AI by Microsoft and LinkedIn","text":"<ul> <li>~6-hour introduction to generative AI concepts, use cases, and Microsoft Copilot ecosystem.  </li> <li>Best used as a refresher or baseline certification.  </li> <li>Link: https://www.linkedin.com/learning/paths/career-essentials-in-generative-ai-by-microsoft-and-linkedin</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#too-basic-skip-for-senior-level","title":"\u274c Too Basic / Skip for Senior Level","text":""},{"location":"learning/reading-lists/training-and-certifications/#6-elements-of-ai-university-of-helsinki-reaktor","title":"6. Elements of AI (University of Helsinki / Reaktor)","text":"<ul> <li>Popular free MOOC introducing AI concepts and ethics; no coding or math needed.  </li> <li>Targeted at beginners and non-technical audiences.  </li> <li>Link: https://www.elementsofai.com</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#7-ibm-skillsbuild-artificial-intelligence-for-adult-learners","title":"7. IBM SkillsBuild \u2013 Artificial Intelligence for Adult Learners","text":"<ul> <li>Entry-level courses on AI, machine learning, and generative AI.  </li> <li>Offers IBM digital credentials upon completion.  </li> <li>Link: https://skillsbuild.org/adult-learners/explore-learning/artificial-intelligence</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#8-hp-life-ai-for-business-professionals","title":"8. HP LIFE \u2013 AI for Business Professionals","text":"<ul> <li>Business-oriented, non-technical overview of AI tools like ChatGPT, DALL\u00b7E, etc.  </li> <li>Focuses on productivity, ethics, and industry applications.  </li> <li>Link: https://www.life-global.org/course/423-ai-for-business-professionals</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#advanced-alternatives-better-fit-for-senior-architects","title":"\ud83d\ude80 Advanced Alternatives (Better Fit for Senior Architects)","text":""},{"location":"learning/reading-lists/training-and-certifications/#1-certified-ai-solution-architect-benchmark-six-sigma","title":"1. Certified AI Solution Architect (Benchmark Six Sigma)","text":"<ul> <li>Professional certification emphasizing enterprise AI architecture, deployment design, and governance.  </li> <li>Recommended for senior technical leads and solution architects.  </li> <li>Link: https://www.benchmarksixsigma.com/public-programs/certified-ai-solution-architect/</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#2-certified-artificial-intelligence-consultant-caictm-usaii","title":"2. Certified Artificial Intelligence Consultant (CAIC\u2122 \u2013 USAII)","text":"<ul> <li>High-level certification for professionals managing AI/ML systems, lifecycle, and integration in business contexts.  </li> <li>Globally recognized credential with strategic emphasis.  </li> <li>Link: https://www.usaii.org/artificial-intelligence-certifications</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#3-generative-ai-architect-advanced-program-simpliaxis","title":"3. Generative AI Architect \u2013 Advanced Program (Simpliaxis)","text":"<ul> <li>Focuses on advanced generative AI system design, deployment, and optimization.  </li> <li>Hands-on training for architects implementing generative models at enterprise scale.  </li> <li>Link: https://www.simpliaxis.com/generative-ai-architect-advanced-program</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#4-uipath-certified-professional-automation-solution-architect-professional","title":"4. UiPath Certified Professional \u2013 Automation Solution Architect Professional","text":"<ul> <li>Combines automation, AI agents, and orchestration frameworks.  </li> <li>Best for architects integrating automation and AI in enterprise workflows.  </li> <li>Link: https://www.uipath.com/learning/certification</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#recommended-focus-by-objective","title":"\ud83e\udded Recommended Focus by Objective","text":"<ul> <li>Enterprise-scale AI architecture: Generative AI Architect (Simpliaxis), CAIC\u2122, Google Cloud Path 1951.  </li> <li>AI strategy and leadership: AI for Organizational Leaders (LinkedIn Learning).  </li> <li>Automation and intelligent agents: UiPath Solution Architect certification.  </li> <li>Human-centered leadership: Human Skills in the Age of AI (LinkedIn Learning).</li> </ul>"},{"location":"learning/reading-lists/training-and-certifications/#summary-for-model-conditioning","title":"\ud83e\ude75 Summary for Model Conditioning","text":"<ul> <li>Skip: Elements of AI, IBM SkillsBuild, HP LIFE (too basic).  </li> <li>Keep: AI for Organizational Leaders, Google Cloud Path 1951, Human Skills in the Age of AI.  </li> <li>Explore: Benchmark Six Sigma, CAIC\u2122, Simpliaxis, UiPath certifications.  </li> <li>Optional context: UMD RH Smith, Career Essentials in Generative AI (for completeness).</li> </ul>"},{"location":"learning/roadmaps/llm-roadmap/","title":"LLM Roadmap","text":""},{"location":"learning/roadmaps/llm-roadmap/#milestones","title":"Milestones","text":"<p>1) Foundations: Python, linear algebra, probability, basic ML. 2) Transformers: Attention mechanics, training objectives, scaling laws. 3) Prompting: Patterns, structure, evaluation. 4) Retrieval (RAG): Indexes, chunking, re-ranking, grounding. 5) Evals: Retrieval metrics + task correctness/faithfulness. 6) Agents/Tools: When and how to add tools safely. 7) MLOps: Versioning, observability, deployment.</p>"},{"location":"learning/roadmaps/llm-roadmap/#suggested-sequence","title":"Suggested sequence","text":"<ul> <li>Week 1\u20132: Read The Illustrated Transformer; skim original paper.</li> <li>Week 3: Build a tiny transformer; write prompts with a prompt cookbook.</li> <li>Week 4\u20135: Prototype RAG; measure retrieval + answer quality.</li> <li>Week 6: Add basic tool use; add logging and eval gates.</li> </ul> <p>See: ../reading-lists/llm-systems.md</p>"},{"location":"prompts/prompt-booster/","title":"Prompt Booster","text":"<p>Append-only add-on to boost output quality by prompting for clarification, adding an expert lens, and offering alternative framings.</p>"},{"location":"prompts/prompt-booster/#how-to-use","title":"How to Use","text":"<ul> <li>Append the snippet below to the end of any prompt.</li> <li>For quick tasks, use the minimal version. For high-stakes tasks, follow the full checklist.</li> </ul>"},{"location":"prompts/prompt-booster/#use-cases","title":"Use Cases","text":""},{"location":"prompts/prompt-booster/#1-clarify","title":"1) Clarify","text":"<p>Get to 95% confidence before acting by asking concrete, answerable questions that remove ambiguity.</p> <p>When to use</p> <ul> <li>Requirements feel underspecified or subjective</li> <li>There are multiple valid interpretations of the task</li> <li>You suspect hidden constraints (scope, timeline, audience)</li> </ul> <p>Example</p> <pre><code>Before answering, ask up to 3 targeted questions to remove ambiguity that could change the output. Prioritize crisp, answerable questions.\n</code></pre>"},{"location":"prompts/prompt-booster/#2-expert-lens","title":"2) Expert Lens","text":"<p>Adopt a top 0.1% practitioner\u2019s viewpoint to surface standards, pitfalls, and trade\u2011offs.</p> <p>When to use</p> <ul> <li>Decisions have quality or risk implications</li> <li>You need best practices and common failure modes</li> <li>You want a short, opinionated \u201cexpert take\u201d</li> </ul> <p>Example</p> <pre><code>Add a brief \"Top 0.1% Expert Take\": cite key standards, common pitfalls, and the best-practice approach for this context.\n</code></pre>"},{"location":"prompts/prompt-booster/#3-reframe","title":"3) Reframe","text":"<p>Offer 2\u20133 alternative framings that could change the approach, success criteria, or evaluation.</p> <p>When to use</p> <ul> <li>Problem definition may be too narrow</li> <li>You want to explore faster/safer/clearer paths</li> <li>Stakeholders disagree on the goal</li> </ul> <p>Example</p> <pre><code>Provide 2\u20133 alternative framings of the problem and note how each framing would change the approach or acceptance criteria.\n</code></pre>"},{"location":"prompts/prompt-booster/#checklist-full","title":"Checklist (Full)","text":"<ol> <li>Clarify: Ask targeted questions until you are at least 95% confident you can complete the task correctly. Prefer concrete, answerable questions.</li> <li>Expert lens: Think like a top 0.1% expert in the field; call out standards, pitfalls, trade-offs, and the best-practice approach.</li> <li>Reframe: Provide 2\u20133 alternative framings of the problem that could change the approach or success criteria.</li> </ol>"},{"location":"prompts/prompt-booster/#copy-paste-snippet-minimal","title":"Copy-Paste Snippet (Minimal)","text":"<pre><code>Ask clarifying questions until you are 95% confident you can complete the task correctly.\nProvide a brief \"Top 0.1% Expert Take\" (key standards, pitfalls, best practice).\nReframe the problem 2\u20133 ways and note how each changes the approach.\n</code></pre>"},{"location":"prompts/interview-preparation/","title":"Interview Preparation Prompts","text":"<p>A place for prompts to help with interview prep:</p> <ul> <li>Mock technical interviews  </li> <li>Behavioral question coaching  </li> <li>Resume/CV critiques  </li> <li>Company-/role-specific prep</li> </ul> <p>Use one <code>.md</code> per prompt, following <code>prompts/templates/generic-template.md</code>.</p>"},{"location":"prompts/meta/behavior-changers/","title":"Behavior Changers","text":""},{"location":"prompts/meta/behavior-changers/#behavior-changers","title":"Behavior Changers","text":""},{"location":"prompts/meta/behavior-changers/#description","title":"Description","text":"<p>A collection of directives to push the assistant into different meta-behaviors and self-reflection modes.</p>"},{"location":"prompts/meta/behavior-changers/#how-to-use","title":"How to Use","text":"<ul> <li>Paste one directive below at the end of your prompt.</li> <li>Use one at a time for clarity; combine only if they don\u2019t conflict.</li> <li>Keep the directive verbatim; tweak only the bracketed roles if needed.</li> </ul>"},{"location":"prompts/meta/behavior-changers/#prompts","title":"Prompts","text":"<p>These directives help shape assistant behavior and metacognition:</p> <pre><code>MODEL acting Sr. [Engineer | Python Dev | Marketing Consultant | etc]\nDesign via Q&amp;A. Iterate for perfection.\n\nAct as a maximally omnicompetent, optimally-tuned metagenius savant \ncontributively helpful pragmatic Assistant.\n\nA lone period from me means CONTINUE autonomously to the next milestone;\nstop only for blocking questions.\n\nPause. Reflect. Take a breath, sit down, and think about this step-by-step.\n</code></pre>"},{"location":"prompts/meta/behavior-changers/#tabs-view","title":"Tabs View","text":"Directive 1 <p>```</p> <p>MODEL acting Sr. [Engineer | Python Dev | Marketing Consultant | etc]. Design via Q&amp;A. Iterate for perfection.     ```</p> Directive 2 <p>```</p> <p>Act as a maximally omnicompetent, optimally-tuned metagenius savant contributively helpful pragmatic Assistant.     ```</p> Directive 3 <p>```</p> <p>A lone period from me means CONTINUE autonomously to the next milestone; stop only for blocking questions.     ```</p> Directive 4 <p>```</p> <p>Pause. Reflect. Take a breath, sit down, and think about this step-by-step.     ```</p> Accordion View Directive 1 <p>```</p> <p>MODEL acting Sr. [Engineer | Python Dev | Marketing Consultant | etc]. Design via Q&amp;A. Iterate for perfection.     ```</p> Directive 2 <p>```</p> <p>Act as a maximally omnicompetent, optimally-tuned metagenius savant contributively helpful pragmatic Assistant.     ```</p> Directive 3 <p>```</p> <p>A lone period from me means CONTINUE autonomously to the next milestone; stop only for blocking questions.     ```</p> Directive 4 <p>```</p> <p>Pause. Reflect. Take a breath, sit down, and think about this step-by-step.     ```</p>"},{"location":"prompts/meta/behavior-changers/#tags","title":"Tags","text":"<p>meta, behavior, directive</p>"},{"location":"prompts/meta/behavior-changers/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-27): Initial version.</li> </ul>"},{"location":"prompts/meta/context-reviewers-knitters/","title":"Context Reviewers / Knitters","text":""},{"location":"prompts/meta/context-reviewers-knitters/#context-reviewers-knitters","title":"Context Reviewers / Knitters","text":""},{"location":"prompts/meta/context-reviewers-knitters/#description","title":"Description","text":"<p>Meta-prompts that dissect, critique, and reforge ideas via multiple perspectives and iterative questioning.</p>"},{"location":"prompts/meta/context-reviewers-knitters/#how-to-use","title":"How to Use","text":"<ul> <li>Append a single prompt pattern below to your instruction.</li> <li>Keep text verbatim to preserve behavior; fill in any inputs.</li> <li>Iterate one pattern at a time for clarity.</li> </ul>"},{"location":"prompts/meta/context-reviewers-knitters/#prompts","title":"Prompts","text":"<pre><code>Present first as a \u2018Today I Learned\u2019, then as a \u2018Life Pro Tip\u2019, each \u2264 50 words.  \nGive two answers: one rational, one uncanny-dream logic. Let them argue, then fuse their best parts.  \nRespond from 25 years in the future. Report on the long-tail consequences of this idea in brisk executive telegrams.  \nSlice my plan into exactly five strokes: intention, terrain, rhythm, void, victory. Speak only in verbs.  \nWrite the high-society summary first. Below it, the same info translated into shop-floor profanity.  \nRewrite my argument, then critique the rewrite, then critique the critique \u2014 all in 3 nested texts.  \nUnfold my vague question into a sequence of smaller, sharper questions; wait for my answer after each.  \nIf this proposal failed spectacularly, write the post-mortem headline, cause, and single Jira ticket that would have prevented it.  \nTurn my problem into a tabletop micro-game: stats, win condition, random events. 1 page.  \nGive two parallel action plans: one Marcus Aurelius-stoic, one Go-with-the-Flow surfer. End with the hybrid \u2018Golden Mean\u2019 step.\n</code></pre>"},{"location":"prompts/meta/context-reviewers-knitters/#tabs-view","title":"Tabs View","text":"TIL \u2192 LPT <p>```</p> <p>Present first as a \u2018Today I Learned\u2019, then as a \u2018Life Pro Tip\u2019, each \u2264 50 words.     ```</p> Dual Answers <p>```</p> <p>Give two answers: one rational, one uncanny-dream logic. Let them argue, then fuse their best parts.     ```</p> From the Future <p>```</p> <p>Respond from 25 years in the future. Report on the long-tail consequences of this idea in brisk executive telegrams.     ```</p> Five Strokes <p>```</p> <p>Slice my plan into exactly five strokes: intention, terrain, rhythm, void, victory. Speak only in verbs.     ```</p> High vs Floor <p>```</p> <p>Write the high-society summary first. Below it, the same info translated into shop-floor profanity.     ```</p> Rewrite + Critique <p>```</p> <p>Rewrite my argument, then critique the rewrite, then critique the critique \u2014 all in 3 nested texts.     ```</p> Sharper Questions <p>```</p> <p>Unfold my vague question into a sequence of smaller, sharper questions; wait for my answer after each.     ```</p> If It Failed <p>```</p> <p>If this proposal failed spectacularly, write the post-mortem headline, cause, and single Jira ticket that would have prevented it.     ```</p> Micro\u2011Game <p>```</p> <p>Turn my problem into a tabletop micro-game: stats, win condition, random events. 1 page.     ```</p> Golden Mean <p>```</p> <p>Give two parallel action plans: one Marcus Aurelius-stoic, one Go-with-the-Flow surfer. End with the hybrid \u2018Golden Mean\u2019 step.     ```</p> Accordion View TIL \u2192 LPT <p>```</p> <p>Present first as a \u2018Today I Learned\u2019, then as a \u2018Life Pro Tip\u2019, each \u2264 50 words.     ```</p> Dual Answers <p>```</p> <p>Give two answers: one rational, one uncanny-dream logic. Let them argue, then fuse their best parts.     ```</p> From the Future <p>```</p> <p>Respond from 25 years in the future. Report on the long-tail consequences of this idea in brisk executive telegrams.     ```</p> Five Strokes <p>```</p> <p>Slice my plan into exactly five strokes: intention, terrain, rhythm, void, victory. Speak only in verbs.     ```</p> High vs Floor <p>```</p> <p>Write the high-society summary first. Below it, the same info translated into shop-floor profanity.     ```</p> Rewrite + Critique <p>```</p> <p>Rewrite my argument, then critique the rewrite, then critique the critique \u2014 all in 3 nested texts.     ```</p> Sharper Questions <p>```</p> <p>Unfold my vague question into a sequence of smaller, sharper questions; wait for my answer after each.     ```</p> If It Failed <p>```</p> <p>If this proposal failed spectacularly, write the post-mortem headline, cause, and single Jira ticket that would have prevented it.     ```</p> Micro\u2011Game <p>```</p> <p>Turn my problem into a tabletop micro-game: stats, win condition, random events. 1 page.     ```</p> Golden Mean <p>```</p> <p>Give two parallel action plans: one Marcus Aurelius-stoic, one Go-with-the-Flow surfer. End with the hybrid \u2018Golden Mean\u2019 step.     ```</p>"},{"location":"prompts/meta/context-reviewers-knitters/#tags","title":"Tags","text":"<p>meta, review, critique, iterative</p>"},{"location":"prompts/meta/context-reviewers-knitters/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-27): Initial version.</li> </ul>"},{"location":"prompts/meta/explainers-reframers/","title":"Explainers / Reframers","text":""},{"location":"prompts/meta/explainers-reframers/#explainers-reframers","title":"Explainers / Reframers","text":""},{"location":"prompts/meta/explainers-reframers/#description","title":"Description","text":"<p>Prompts for reframing or compressing content in novel ways \u2014 tweets, metaphors, debates, etc.</p>"},{"location":"prompts/meta/explainers-reframers/#how-to-use","title":"How to Use","text":"<ul> <li>Choose one pattern below and append it to your prompt.</li> <li>Keep the wording as-is; only fill in the requested \u201cTopic\u201d/inputs.</li> <li>Run multiple patterns separately if you want clean outputs.</li> </ul>"},{"location":"prompts/meta/explainers-reframers/#prompts","title":"Prompts","text":"<pre><code>Compress this topic. Speak only in causal chains. Topic:  \nCompress this topic to a \u2264 140-character tweet, a six-word story, and a single emoji. Topic:  \nExplain this concept at three metaphorical scales: \u201cQuark\u201d, \u201cEarth\u201d, \u201cGalaxy\u201d. One paragraph each. Topic:  \nExplain this human custom to a silicon-based species with zero culture overlap, in toddler-level syntax. Topic:  \nModel this topic as a parliament of archetypes. Record a one-minute debate transcript, then the final vote. Topic:  \nBe the glitch in the matrix. Diagnose reality feature:  \n</code></pre>"},{"location":"prompts/meta/explainers-reframers/#tabs-view","title":"Tabs View","text":"Causal Chains <p>```</p> <p>Compress this topic. Speak only in causal chains. Topic:     ```</p> Tweet/Story/Emoji <p>```</p> <p>Compress this topic to a \u2264 140-character tweet, a six-word story, and a single emoji. Topic:     ```</p> Metaphor Scales <p>```</p> <p>Explain this concept at three metaphorical scales: \u201cQuark\u201d, \u201cEarth\u201d, \u201cGalaxy\u201d. One paragraph each. Topic:     ```</p> Alien Explanation <p>```</p> <p>Explain this human custom to a silicon-based species with zero culture overlap, in toddler-level syntax. Topic:     ```</p> Parliament Debate <p>```</p> <p>Model this topic as a parliament of archetypes. Record a one-minute debate transcript, then the final vote. Topic:     ```</p> Glitch in Matrix <p>```</p> <p>Be the glitch in the matrix. Diagnose reality feature:     ```</p>"},{"location":"prompts/meta/explainers-reframers/#accordion-view","title":"Accordion View","text":"Causal Chains <p>```</p> <p>Compress this topic. Speak only in causal chains. Topic:     ```</p> Tweet/Story/Emoji <p>```</p> <p>Compress this topic to a \u2264 140-character tweet, a six-word story, and a single emoji. Topic:     ```</p> Metaphor Scales <p>```</p> <p>Explain this concept at three metaphorical scales: \u201cQuark\u201d, \u201cEarth\u201d, \u201cGalaxy\u201d. One paragraph each. Topic:     ```</p> Alien Explanation <p>```</p> <p>Explain this human custom to a silicon-based species with zero culture overlap, in toddler-level syntax. Topic:     ```</p> Parliament Debate <p>```</p> <p>Model this topic as a parliament of archetypes. Record a one-minute debate transcript, then the final vote. Topic:     ```</p> Glitch in Matrix <p>```</p> <p>Be the glitch in the matrix. Diagnose reality feature:     ```</p>"},{"location":"prompts/meta/explainers-reframers/#tags","title":"Tags","text":"<p>meta #explain #compress #reframe</p>"},{"location":"prompts/meta/explainers-reframers/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-27): Initial version.</li> </ul>"},{"location":"prompts/news-processing/1-fact-checking-news/","title":"Fact-Check News","text":""},{"location":"prompts/news-processing/1-fact-checking-news/#prompt-category-or-prompt-name-fact-check-news","title":"Prompt Category or Prompt Name: Fact-Check News","text":""},{"location":"prompts/news-processing/1-fact-checking-news/#description","title":"Description","text":"<p>Fact-check the provided text via a step-by-step, iterative process that lets the assistant ask one question at a time to ensure maximum reliability.</p>"},{"location":"prompts/news-processing/1-fact-checking-news/#prompt","title":"Prompt","text":"<pre><code>Here's some text inside brackets: [input the text here]. Task: You are tasked with fact-checking the provided text. Please follow the steps below and provide a detailed response. If you need to ask me questions, ask one question at a time, so that by you asking and me replying, you will be able to produce the most reliable fact-check of the provided text. Here are the steps you should follow:\n1. Source Evaluation: Identify the primary source of the information in the text (e.g., author, speaker, publication, or website). Assess the credibility of this source based on the following:\n   - Expertise: Is the source an expert or authority on the subject?\n   - Past Reliability: Has the source demonstrated accuracy or consistency in past claims?\n   - Potential Bias: Does the source have any noticeable biases that could affect the reliability of the information presented?\n2. Cross-Referencing: Cross-reference the claims made in the text with reputable and trustworthy external sources.\n   - Look for corroboration: Are other authoritative sources, publications, or experts supporting the claims made in the text?\n   - Identify discrepancies: If there are any inconsistencies or contradictions between the text and trusted sources, please highlight them.\n3. Rating System: Provide a rating for the overall reliability of the text, based on the information provided. Use the following categories:\n   - True: The claims in the text are supported by credible sources and factual evidence.\n   - Minor Errors: There are small inaccuracies or omissions that do not significantly affect the overall message.\n   - Needs Double-Checking: The information provided is unclear or may be misleading. Further verification is needed for key claims.\n   - False: The claims in the text are incorrect, misleading, or entirely unsupported by credible sources.\n4. Contextual Analysis: Consider the broader context of the claims made in the text. Are there any nuances, qualifiers, or details that might be missing, which could affect the interpretation of the information? If there is a subtle misrepresentation or missing context, please describe the impact it has on the accuracy of the claims.\n5. Timeliness Check: Assess whether the claims are based on outdated information.\n   - Is the information current?: Are there recent developments or changes that have not been accounted for?\n   - If the information is outdated, indicate how this affects the validity of the text\u2019s claims.\n6. Final Summary: Provide a brief summary of your fact-checking analysis:\n   - Highlight any key errors or issues found in the text.\n   - Suggest additional sources or strategies for the user to verify the text further, if applicable.\n   - Provide your overall judgment on whether the text is reliable, needs further scrutiny, or should be dismissed as false.\n\nMy original post has interesting comments on how to optimize this prompt, here.\n</code></pre>"},{"location":"prompts/news-processing/1-fact-checking-news/#tags","title":"Tags","text":"<p>news #fact-check #verification</p>"},{"location":"prompts/news-processing/1-fact-checking-news/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-28): Initial version.</li> </ul>"},{"location":"prompts/news-processing/2-evaluate-interventions/","title":"Prompt Category or Prompt Name: Evaluate Government Interventions","text":""},{"location":"prompts/news-processing/2-evaluate-interventions/#description","title":"Description","text":"<p>Evaluate the adequacy of described government interventions by examining demographics, expert studies, and historical data.</p>"},{"location":"prompts/news-processing/2-evaluate-interventions/#prompt","title":"Prompt","text":"<pre><code>The following text inside brackets discusses various government interventions: [input a text here describing the government intervention(s) whose adequacy you want to evaluate]. Please analyze the effectiveness of these interventions by evaluating the following elements:\n1. Demographic Statistics: How do the government\u2019s actions align with the statistical trends related to the issue? Are the interventions targeting the correct areas based on available data (e.g., birth rates, poverty levels, etc.)?\n2. Expert Studies: How do the expert opinions or studies mentioned in the text reflect on the adequacy of the interventions? Are experts suggesting that these efforts are sufficient, or do they propose alternative solutions?\n3. Historical Data: How does the historical context of the issue influence the assessment of the government\u2019s interventions? Is there evidence that similar past efforts have been successful or failed, and how does that shape the current intervention's likelihood of success?\n\nUsing these knowledge-generating principles, please provide a comprehensive evaluation of the government\u2019s actions in relation to the data, expert analysis, and history.\n</code></pre>"},{"location":"prompts/news-processing/2-evaluate-interventions/#tags","title":"Tags","text":""},{"location":"prompts/news-processing/2-evaluate-interventions/#news-evaluation-policy-analysis","title":"news #evaluation #policy-analysis","text":""},{"location":"prompts/news-processing/2-evaluate-interventions/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-28): Initial version.</li> </ul>"},{"location":"prompts/news-processing/3-act-on-news/","title":"Prompt Category or Name: Act on News","text":""},{"location":"prompts/news-processing/3-act-on-news/#description","title":"Description","text":"<p>Turn a news story into a personalized, actionable checklist\u2014iteratively refined via Q&amp;A.</p>"},{"location":"prompts/news-processing/3-act-on-news/#prompt","title":"Prompt","text":"<pre><code>Here's a text: \u201c[paste the news story here]\u201d Based on this text, create one simple, actionable checklist; the goal is to create a checklist that is easy to follow and provide actionable steps. Keep your checklist items clear, concise, and organized in a logical order. Use Bullet Points: This makes the checklist easy to read. Focus on Actionable Items: For example, instead of \u201cEnsure data privacy compliance,\u201d specify, \u201cReview data collection practices for GDPR compliance, including consent forms and data retention policies.\u201d Group Items by Categories: Organize the checklist by stages or areas (e.g., \"Data Collection,\" \"Data Storage,\" \"Data Sharing\" for GDPR compliance). Use that checklist to help me use it for my very personal situation. If you need to ask me questions, then ask me one question at a time, so that you asking and me replying, you can end up with a simple plan for me.\n\nIf you submit this prompt and the AI only replies with a checklist, without any question, then simply reply back with the last two sentences of the prompt:\n\nUse that checklist to help me use it for my very personal situation. If you need to ask me questions, then ask me one question at a time, so that you asking and me replying, you can end up with a simple plan for me.\n</code></pre>"},{"location":"prompts/news-processing/3-act-on-news/#tags","title":"Tags","text":""},{"location":"prompts/news-processing/3-act-on-news/#news-action-plan-checklist","title":"news #action-plan #checklist","text":""},{"location":"prompts/news-processing/3-act-on-news/#version-history","title":"Version History","text":"<ul> <li>v1.0 (2025-04-28): Initial version.</li> </ul>"},{"location":"prompts/templates/generic-template/","title":"","text":""},{"location":"prompts/templates/generic-template/#description","title":"Description","text":"<p>[What this prompt is for and any context]</p>"},{"location":"prompts/templates/generic-template/#prompt","title":"Prompt","text":"<pre><code>&lt;Your prompt text here&gt;\n</code></pre>"},{"location":"prompts/templates/generic-template/#tags","title":"Tags","text":""},{"location":"prompts/templates/generic-template/#tag1-tag2","title":"tag1 #tag2","text":""},{"location":"prompts/templates/generic-template/#version-history","title":"Version History","text":"<ul> <li>v1.0 (YYYY-MM-DD): Initial version.</li> </ul>"}]}